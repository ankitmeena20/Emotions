{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdxwpf0bGdq0"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN4ZdCEVGojS"
      },
      "source": [
        "def plotter(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'],label='train loss')\n",
        "  plt.plot(history.history['val_loss'],label='test loss')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('losses')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'],label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'],label='test accuracy')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nUFvHQGnsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6c4176c7-879b-400a-a96f-c04db261a97d"
      },
      "source": [
        "missing_values = [\"?\"]\n",
        "Features = pd.read_csv('/content/features.csv', na_values=missing_values)\n",
        "Features.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.272267</td>\n",
              "      <td>0.689451</td>\n",
              "      <td>0.708028</td>\n",
              "      <td>0.666473</td>\n",
              "      <td>0.715468</td>\n",
              "      <td>0.694820</td>\n",
              "      <td>0.627661</td>\n",
              "      <td>0.632560</td>\n",
              "      <td>0.687715</td>\n",
              "      <td>0.712157</td>\n",
              "      <td>0.706116</td>\n",
              "      <td>0.696561</td>\n",
              "      <td>0.666424</td>\n",
              "      <td>-505.009247</td>\n",
              "      <td>64.000099</td>\n",
              "      <td>-2.749660</td>\n",
              "      <td>16.950371</td>\n",
              "      <td>-1.089467</td>\n",
              "      <td>-2.046432</td>\n",
              "      <td>-7.829981</td>\n",
              "      <td>-8.716751</td>\n",
              "      <td>-19.273317</td>\n",
              "      <td>-5.294091</td>\n",
              "      <td>-5.584455</td>\n",
              "      <td>-5.783628</td>\n",
              "      <td>-1.870991</td>\n",
              "      <td>-7.146638</td>\n",
              "      <td>-3.675263</td>\n",
              "      <td>-0.451763</td>\n",
              "      <td>-11.253410</td>\n",
              "      <td>-3.521277</td>\n",
              "      <td>-3.482842</td>\n",
              "      <td>-5.802355</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.018095</td>\n",
              "      <td>0.134511</td>\n",
              "      <td>0.229614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>0.002306</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001945</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.003231</td>\n",
              "      <td>0.002353</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.002131</td>\n",
              "      <td>0.001839</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001006</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>1.498768e-05</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.262035</td>\n",
              "      <td>0.603476</td>\n",
              "      <td>0.668302</td>\n",
              "      <td>0.692199</td>\n",
              "      <td>0.709884</td>\n",
              "      <td>0.658301</td>\n",
              "      <td>0.605176</td>\n",
              "      <td>0.609343</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>0.689348</td>\n",
              "      <td>0.702884</td>\n",
              "      <td>0.687124</td>\n",
              "      <td>0.663653</td>\n",
              "      <td>-626.262817</td>\n",
              "      <td>93.897247</td>\n",
              "      <td>-0.691273</td>\n",
              "      <td>17.833763</td>\n",
              "      <td>9.502007</td>\n",
              "      <td>2.030928</td>\n",
              "      <td>-2.721135</td>\n",
              "      <td>-8.514406</td>\n",
              "      <td>-12.427499</td>\n",
              "      <td>-6.575863</td>\n",
              "      <td>-0.015912</td>\n",
              "      <td>-2.750585</td>\n",
              "      <td>0.777975</td>\n",
              "      <td>-5.365466</td>\n",
              "      <td>-0.337154</td>\n",
              "      <td>1.482861</td>\n",
              "      <td>-8.703282</td>\n",
              "      <td>-2.764846</td>\n",
              "      <td>-1.618086</td>\n",
              "      <td>-1.523441</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.008725</td>\n",
              "      <td>0.090577</td>\n",
              "      <td>0.060794</td>\n",
              "      <td>0.002684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>8.432723e-07</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.195466</td>\n",
              "      <td>0.628032</td>\n",
              "      <td>0.687169</td>\n",
              "      <td>0.651985</td>\n",
              "      <td>0.621273</td>\n",
              "      <td>0.604192</td>\n",
              "      <td>0.640623</td>\n",
              "      <td>0.626136</td>\n",
              "      <td>0.652430</td>\n",
              "      <td>0.685134</td>\n",
              "      <td>0.653014</td>\n",
              "      <td>0.649654</td>\n",
              "      <td>0.632400</td>\n",
              "      <td>-535.881226</td>\n",
              "      <td>82.281357</td>\n",
              "      <td>-9.010551</td>\n",
              "      <td>20.842283</td>\n",
              "      <td>5.421832</td>\n",
              "      <td>-3.754339</td>\n",
              "      <td>-10.541499</td>\n",
              "      <td>-13.465772</td>\n",
              "      <td>-27.917681</td>\n",
              "      <td>-6.894572</td>\n",
              "      <td>-3.809465</td>\n",
              "      <td>-10.429282</td>\n",
              "      <td>0.157545</td>\n",
              "      <td>-7.953777</td>\n",
              "      <td>-6.011678</td>\n",
              "      <td>2.456674</td>\n",
              "      <td>-10.448029</td>\n",
              "      <td>-6.485257</td>\n",
              "      <td>-4.687830</td>\n",
              "      <td>-3.553447</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.016251</td>\n",
              "      <td>0.110550</td>\n",
              "      <td>0.186236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.000436</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>2.326331e-06</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.173769</td>\n",
              "      <td>0.720864</td>\n",
              "      <td>0.685492</td>\n",
              "      <td>0.655122</td>\n",
              "      <td>0.652557</td>\n",
              "      <td>0.587786</td>\n",
              "      <td>0.550012</td>\n",
              "      <td>0.638170</td>\n",
              "      <td>0.707171</td>\n",
              "      <td>0.648498</td>\n",
              "      <td>0.604207</td>\n",
              "      <td>0.638241</td>\n",
              "      <td>0.707306</td>\n",
              "      <td>-526.520569</td>\n",
              "      <td>84.466164</td>\n",
              "      <td>-6.822329</td>\n",
              "      <td>22.756920</td>\n",
              "      <td>8.021371</td>\n",
              "      <td>-0.836710</td>\n",
              "      <td>-6.375116</td>\n",
              "      <td>-13.950517</td>\n",
              "      <td>-15.801805</td>\n",
              "      <td>-1.701238</td>\n",
              "      <td>-3.240356</td>\n",
              "      <td>-2.120920</td>\n",
              "      <td>-1.001574</td>\n",
              "      <td>-5.576652</td>\n",
              "      <td>-0.277861</td>\n",
              "      <td>0.180505</td>\n",
              "      <td>-5.214784</td>\n",
              "      <td>-4.889361</td>\n",
              "      <td>-1.206443</td>\n",
              "      <td>2.497521</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.052773</td>\n",
              "      <td>0.284222</td>\n",
              "      <td>0.078999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>0.001356</td>\n",
              "      <td>0.000967</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>4.691918e-06</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.207284</td>\n",
              "      <td>0.692981</td>\n",
              "      <td>0.737456</td>\n",
              "      <td>0.726056</td>\n",
              "      <td>0.685032</td>\n",
              "      <td>0.636497</td>\n",
              "      <td>0.568223</td>\n",
              "      <td>0.528898</td>\n",
              "      <td>0.598124</td>\n",
              "      <td>0.635435</td>\n",
              "      <td>0.643268</td>\n",
              "      <td>0.671737</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>-591.298523</td>\n",
              "      <td>92.935883</td>\n",
              "      <td>-4.376369</td>\n",
              "      <td>22.136271</td>\n",
              "      <td>9.728477</td>\n",
              "      <td>-3.868228</td>\n",
              "      <td>-4.231765</td>\n",
              "      <td>-12.517565</td>\n",
              "      <td>-17.417633</td>\n",
              "      <td>-6.273466</td>\n",
              "      <td>-7.159021</td>\n",
              "      <td>-2.124696</td>\n",
              "      <td>-2.085358</td>\n",
              "      <td>-9.489192</td>\n",
              "      <td>-3.802913</td>\n",
              "      <td>-1.608241</td>\n",
              "      <td>-9.055273</td>\n",
              "      <td>-6.693238</td>\n",
              "      <td>-5.338201</td>\n",
              "      <td>-0.922801</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.001787</td>\n",
              "      <td>0.018344</td>\n",
              "      <td>0.063987</td>\n",
              "      <td>0.039720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.218449e-07</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1  ...       159           160  labels\n",
              "0           0  0.272267  0.689451  ...  0.000143  1.498768e-05   angry\n",
              "1           1  0.262035  0.603476  ...  0.000011  8.432723e-07    calm\n",
              "2           2  0.195466  0.628032  ...  0.000031  2.326331e-06     sad\n",
              "3           3  0.173769  0.720864  ...  0.000074  4.691918e-06    fear\n",
              "4           4  0.207284  0.692981  ...  0.000008  4.218449e-07     sad\n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B88N9_mJ6S_Y"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "temp = shuffle(Features)\n",
        "# temp[:10]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5kFASY7Fql"
      },
      "source": [
        "df = np.random.rand(len(temp)) < 0.8\n",
        "train = temp[df]\n",
        "test = temp[~df]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh5rIXz87gEE"
      },
      "source": [
        "trainfeatures = train.iloc[:, :-1]\n",
        "trainlabel = train.iloc[:, -1:]\n",
        "testfeatures = test.iloc[:, :-1]\n",
        "testlabel = test.iloc[:, -1:]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fqDHjxq7vUF"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train = np.array(trainfeatures)\n",
        "y_train = np.array(trainlabel)\n",
        "X_test = np.array(testfeatures)\n",
        "y_test = np.array(testlabel)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKd_61MS76ML"
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3MRQgDr8Aqj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers, optimizers\n",
        "model = models.Sequential()\n",
        "model.add(tf.keras.layers.Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=(8)))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Conv1D(64, 5,padding='same',))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
        "opt = keras.optimizers.Adam(lr=0.0001)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-0SUzFP-zpU"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBpYQEyA_IeQ",
        "outputId": "b0a1a363-8dd9-4957-a732-25f7e7ced457"
      },
      "source": [
        "history=model.fit(x_traincnn, y_train, batch_size=256, epochs=1000, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 2s 114ms/step - loss: 3.6521 - accuracy: 0.1272 - val_loss: 2.1262 - val_accuracy: 0.1133\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.9010 - accuracy: 0.1523 - val_loss: 2.0670 - val_accuracy: 0.0809\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.6313 - accuracy: 0.1285 - val_loss: 2.0689 - val_accuracy: 0.1683\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 2.4241 - accuracy: 0.1426 - val_loss: 2.0659 - val_accuracy: 0.1974\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.3713 - accuracy: 0.1374 - val_loss: 2.0651 - val_accuracy: 0.2201\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.2440 - accuracy: 0.1328 - val_loss: 2.0630 - val_accuracy: 0.1909\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1963 - accuracy: 0.1427 - val_loss: 2.0633 - val_accuracy: 0.1909\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.2242 - accuracy: 0.1193 - val_loss: 2.0615 - val_accuracy: 0.1974\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1566 - accuracy: 0.1450 - val_loss: 2.0596 - val_accuracy: 0.2362\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1554 - accuracy: 0.1695 - val_loss: 2.0593 - val_accuracy: 0.2136\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1054 - accuracy: 0.1594 - val_loss: 2.0572 - val_accuracy: 0.2039\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1143 - accuracy: 0.1626 - val_loss: 2.0553 - val_accuracy: 0.1942\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1176 - accuracy: 0.1416 - val_loss: 2.0523 - val_accuracy: 0.1748\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0975 - accuracy: 0.1584 - val_loss: 2.0497 - val_accuracy: 0.1780\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0987 - accuracy: 0.1478 - val_loss: 2.0469 - val_accuracy: 0.2136\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1103 - accuracy: 0.1698 - val_loss: 2.0428 - val_accuracy: 0.2168\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0789 - accuracy: 0.1528 - val_loss: 2.0389 - val_accuracy: 0.2136\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0877 - accuracy: 0.1520 - val_loss: 2.0330 - val_accuracy: 0.2168\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0845 - accuracy: 0.1564 - val_loss: 2.0270 - val_accuracy: 0.2233\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0798 - accuracy: 0.1563 - val_loss: 2.0201 - val_accuracy: 0.1974\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0578 - accuracy: 0.1770 - val_loss: 2.0153 - val_accuracy: 0.1909\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0538 - accuracy: 0.1661 - val_loss: 2.0095 - val_accuracy: 0.1845\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0310 - accuracy: 0.1798 - val_loss: 1.9997 - val_accuracy: 0.1942\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0550 - accuracy: 0.1837 - val_loss: 1.9929 - val_accuracy: 0.2071\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0451 - accuracy: 0.1925 - val_loss: 1.9888 - val_accuracy: 0.2168\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0426 - accuracy: 0.1835 - val_loss: 1.9877 - val_accuracy: 0.2104\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0378 - accuracy: 0.1809 - val_loss: 1.9853 - val_accuracy: 0.2136\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.0617 - accuracy: 0.1568 - val_loss: 1.9811 - val_accuracy: 0.2039\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0315 - accuracy: 0.1612 - val_loss: 1.9754 - val_accuracy: 0.1877\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.0288 - accuracy: 0.1817 - val_loss: 1.9692 - val_accuracy: 0.1974\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0206 - accuracy: 0.1855 - val_loss: 1.9640 - val_accuracy: 0.2168\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0552 - accuracy: 0.1627 - val_loss: 1.9594 - val_accuracy: 0.2168\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0145 - accuracy: 0.1836 - val_loss: 1.9566 - val_accuracy: 0.2330\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0086 - accuracy: 0.2138 - val_loss: 1.9531 - val_accuracy: 0.2362\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0113 - accuracy: 0.1896 - val_loss: 1.9508 - val_accuracy: 0.2168\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0090 - accuracy: 0.1788 - val_loss: 1.9479 - val_accuracy: 0.2265\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0378 - accuracy: 0.1710 - val_loss: 1.9437 - val_accuracy: 0.2654\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0124 - accuracy: 0.1913 - val_loss: 1.9418 - val_accuracy: 0.2816\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9909 - accuracy: 0.2007 - val_loss: 1.9401 - val_accuracy: 0.2848\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9919 - accuracy: 0.1888 - val_loss: 1.9372 - val_accuracy: 0.2945\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9964 - accuracy: 0.1993 - val_loss: 1.9332 - val_accuracy: 0.2977\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9842 - accuracy: 0.2214 - val_loss: 1.9315 - val_accuracy: 0.3107\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0053 - accuracy: 0.2061 - val_loss: 1.9304 - val_accuracy: 0.3107\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9872 - accuracy: 0.2006 - val_loss: 1.9285 - val_accuracy: 0.3107\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9909 - accuracy: 0.1906 - val_loss: 1.9274 - val_accuracy: 0.2945\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9907 - accuracy: 0.2019 - val_loss: 1.9278 - val_accuracy: 0.2718\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9760 - accuracy: 0.1913 - val_loss: 1.9256 - val_accuracy: 0.2330\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9930 - accuracy: 0.1910 - val_loss: 1.9226 - val_accuracy: 0.2039\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9733 - accuracy: 0.1922 - val_loss: 1.9169 - val_accuracy: 0.2265\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9769 - accuracy: 0.2103 - val_loss: 1.9120 - val_accuracy: 0.2427\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9683 - accuracy: 0.2050 - val_loss: 1.9079 - val_accuracy: 0.2589\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9464 - accuracy: 0.1945 - val_loss: 1.9035 - val_accuracy: 0.2718\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9758 - accuracy: 0.1863 - val_loss: 1.8983 - val_accuracy: 0.2751\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9559 - accuracy: 0.2230 - val_loss: 1.8917 - val_accuracy: 0.2783\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9576 - accuracy: 0.2261 - val_loss: 1.8869 - val_accuracy: 0.2718\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9680 - accuracy: 0.1911 - val_loss: 1.8853 - val_accuracy: 0.2783\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9693 - accuracy: 0.2112 - val_loss: 1.8841 - val_accuracy: 0.2816\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9482 - accuracy: 0.2140 - val_loss: 1.8835 - val_accuracy: 0.2848\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9655 - accuracy: 0.2068 - val_loss: 1.8812 - val_accuracy: 0.2848\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9741 - accuracy: 0.2135 - val_loss: 1.8808 - val_accuracy: 0.2816\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9763 - accuracy: 0.1945 - val_loss: 1.8809 - val_accuracy: 0.2848\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9477 - accuracy: 0.2229 - val_loss: 1.8778 - val_accuracy: 0.2816\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9577 - accuracy: 0.1924 - val_loss: 1.8756 - val_accuracy: 0.2880\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.9772 - accuracy: 0.1996 - val_loss: 1.8752 - val_accuracy: 0.2945\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9511 - accuracy: 0.2037 - val_loss: 1.8748 - val_accuracy: 0.2880\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9599 - accuracy: 0.2017 - val_loss: 1.8740 - val_accuracy: 0.2654\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9626 - accuracy: 0.1961 - val_loss: 1.8735 - val_accuracy: 0.2557\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9446 - accuracy: 0.2147 - val_loss: 1.8708 - val_accuracy: 0.2945\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9553 - accuracy: 0.1941 - val_loss: 1.8682 - val_accuracy: 0.2783\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9512 - accuracy: 0.1945 - val_loss: 1.8647 - val_accuracy: 0.2751\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9305 - accuracy: 0.2212 - val_loss: 1.8622 - val_accuracy: 0.2718\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9646 - accuracy: 0.2093 - val_loss: 1.8635 - val_accuracy: 0.2718\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9228 - accuracy: 0.2348 - val_loss: 1.8643 - val_accuracy: 0.2686\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9213 - accuracy: 0.2193 - val_loss: 1.8608 - val_accuracy: 0.2718\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9354 - accuracy: 0.2210 - val_loss: 1.8551 - val_accuracy: 0.2816\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9164 - accuracy: 0.2007 - val_loss: 1.8503 - val_accuracy: 0.2718\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9216 - accuracy: 0.2327 - val_loss: 1.8481 - val_accuracy: 0.2751\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9427 - accuracy: 0.2103 - val_loss: 1.8455 - val_accuracy: 0.2718\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9393 - accuracy: 0.1951 - val_loss: 1.8438 - val_accuracy: 0.2718\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8965 - accuracy: 0.2348 - val_loss: 1.8430 - val_accuracy: 0.2848\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9356 - accuracy: 0.2204 - val_loss: 1.8461 - val_accuracy: 0.2816\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8977 - accuracy: 0.2399 - val_loss: 1.8445 - val_accuracy: 0.2718\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9272 - accuracy: 0.2289 - val_loss: 1.8414 - val_accuracy: 0.2686\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9210 - accuracy: 0.2250 - val_loss: 1.8393 - val_accuracy: 0.2751\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9077 - accuracy: 0.2205 - val_loss: 1.8369 - val_accuracy: 0.2816\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9084 - accuracy: 0.2356 - val_loss: 1.8352 - val_accuracy: 0.2848\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9159 - accuracy: 0.2286 - val_loss: 1.8342 - val_accuracy: 0.2880\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9196 - accuracy: 0.2150 - val_loss: 1.8309 - val_accuracy: 0.2816\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8800 - accuracy: 0.2456 - val_loss: 1.8246 - val_accuracy: 0.2880\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.9354 - accuracy: 0.2294 - val_loss: 1.8222 - val_accuracy: 0.2751\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8976 - accuracy: 0.2534 - val_loss: 1.8212 - val_accuracy: 0.2880\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9187 - accuracy: 0.2163 - val_loss: 1.8199 - val_accuracy: 0.2977\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8952 - accuracy: 0.2558 - val_loss: 1.8160 - val_accuracy: 0.3010\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9111 - accuracy: 0.2284 - val_loss: 1.8137 - val_accuracy: 0.2880\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9011 - accuracy: 0.2223 - val_loss: 1.8070 - val_accuracy: 0.2686\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8954 - accuracy: 0.2536 - val_loss: 1.8024 - val_accuracy: 0.2783\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.9136 - accuracy: 0.2324 - val_loss: 1.8042 - val_accuracy: 0.2816\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9016 - accuracy: 0.2559 - val_loss: 1.8047 - val_accuracy: 0.3074\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8931 - accuracy: 0.2120 - val_loss: 1.8052 - val_accuracy: 0.2977\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8971 - accuracy: 0.2509 - val_loss: 1.8055 - val_accuracy: 0.3042\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9059 - accuracy: 0.2420 - val_loss: 1.8069 - val_accuracy: 0.3042\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9237 - accuracy: 0.2268 - val_loss: 1.8107 - val_accuracy: 0.3398\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8912 - accuracy: 0.2561 - val_loss: 1.8061 - val_accuracy: 0.3139\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8830 - accuracy: 0.2483 - val_loss: 1.8026 - val_accuracy: 0.3074\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8900 - accuracy: 0.2523 - val_loss: 1.7991 - val_accuracy: 0.3042\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8849 - accuracy: 0.2291 - val_loss: 1.7942 - val_accuracy: 0.3042\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8853 - accuracy: 0.2273 - val_loss: 1.7909 - val_accuracy: 0.3139\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8766 - accuracy: 0.2514 - val_loss: 1.7907 - val_accuracy: 0.3107\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8714 - accuracy: 0.2483 - val_loss: 1.7891 - val_accuracy: 0.3236\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8679 - accuracy: 0.2187 - val_loss: 1.7899 - val_accuracy: 0.3495\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8699 - accuracy: 0.2343 - val_loss: 1.7844 - val_accuracy: 0.3430\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8660 - accuracy: 0.2428 - val_loss: 1.7788 - val_accuracy: 0.3172\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8586 - accuracy: 0.2599 - val_loss: 1.7766 - val_accuracy: 0.3333\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8497 - accuracy: 0.2662 - val_loss: 1.7764 - val_accuracy: 0.3107\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8481 - accuracy: 0.2739 - val_loss: 1.7809 - val_accuracy: 0.3301\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8632 - accuracy: 0.2585 - val_loss: 1.7763 - val_accuracy: 0.3204\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8827 - accuracy: 0.2513 - val_loss: 1.7752 - val_accuracy: 0.3301\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8622 - accuracy: 0.2514 - val_loss: 1.7740 - val_accuracy: 0.3333\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8571 - accuracy: 0.2386 - val_loss: 1.7740 - val_accuracy: 0.3398\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8632 - accuracy: 0.2370 - val_loss: 1.7746 - val_accuracy: 0.3333\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8349 - accuracy: 0.2638 - val_loss: 1.7713 - val_accuracy: 0.3463\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8462 - accuracy: 0.2642 - val_loss: 1.7654 - val_accuracy: 0.3269\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8375 - accuracy: 0.2537 - val_loss: 1.7615 - val_accuracy: 0.3366\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8381 - accuracy: 0.2701 - val_loss: 1.7578 - val_accuracy: 0.3463\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8587 - accuracy: 0.2578 - val_loss: 1.7576 - val_accuracy: 0.3560\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8391 - accuracy: 0.2753 - val_loss: 1.7567 - val_accuracy: 0.3463\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8660 - accuracy: 0.2542 - val_loss: 1.7578 - val_accuracy: 0.3463\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.8420 - accuracy: 0.2558 - val_loss: 1.7604 - val_accuracy: 0.3398\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8606 - accuracy: 0.2559 - val_loss: 1.7615 - val_accuracy: 0.3430\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8539 - accuracy: 0.2655 - val_loss: 1.7618 - val_accuracy: 0.3398\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8352 - accuracy: 0.2682 - val_loss: 1.7598 - val_accuracy: 0.3398\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8615 - accuracy: 0.2592 - val_loss: 1.7568 - val_accuracy: 0.3366\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8564 - accuracy: 0.2372 - val_loss: 1.7524 - val_accuracy: 0.3333\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8349 - accuracy: 0.2518 - val_loss: 1.7491 - val_accuracy: 0.3398\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8295 - accuracy: 0.2698 - val_loss: 1.7465 - val_accuracy: 0.3301\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.8429 - accuracy: 0.2704 - val_loss: 1.7484 - val_accuracy: 0.3495\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8222 - accuracy: 0.2721 - val_loss: 1.7481 - val_accuracy: 0.3592\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8193 - accuracy: 0.2846 - val_loss: 1.7443 - val_accuracy: 0.3657\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8539 - accuracy: 0.2565 - val_loss: 1.7409 - val_accuracy: 0.3236\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8479 - accuracy: 0.2712 - val_loss: 1.7392 - val_accuracy: 0.3366\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8382 - accuracy: 0.2530 - val_loss: 1.7414 - val_accuracy: 0.3495\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8257 - accuracy: 0.2535 - val_loss: 1.7387 - val_accuracy: 0.3366\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8360 - accuracy: 0.2593 - val_loss: 1.7382 - val_accuracy: 0.3139\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8195 - accuracy: 0.2663 - val_loss: 1.7367 - val_accuracy: 0.3366\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7923 - accuracy: 0.3162 - val_loss: 1.7344 - val_accuracy: 0.3430\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8302 - accuracy: 0.2602 - val_loss: 1.7304 - val_accuracy: 0.3333\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8245 - accuracy: 0.2703 - val_loss: 1.7325 - val_accuracy: 0.3074\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8266 - accuracy: 0.2862 - val_loss: 1.7333 - val_accuracy: 0.3204\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8173 - accuracy: 0.2616 - val_loss: 1.7379 - val_accuracy: 0.3398\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8202 - accuracy: 0.2873 - val_loss: 1.7291 - val_accuracy: 0.3269\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8282 - accuracy: 0.2809 - val_loss: 1.7206 - val_accuracy: 0.3204\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8285 - accuracy: 0.2684 - val_loss: 1.7198 - val_accuracy: 0.3236\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7812 - accuracy: 0.2871 - val_loss: 1.7226 - val_accuracy: 0.3269\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8021 - accuracy: 0.2758 - val_loss: 1.7207 - val_accuracy: 0.3301\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7765 - accuracy: 0.2842 - val_loss: 1.7110 - val_accuracy: 0.3430\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8149 - accuracy: 0.2739 - val_loss: 1.7050 - val_accuracy: 0.3560\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8000 - accuracy: 0.2791 - val_loss: 1.7018 - val_accuracy: 0.3398\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7930 - accuracy: 0.3057 - val_loss: 1.7058 - val_accuracy: 0.3430\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7989 - accuracy: 0.2690 - val_loss: 1.7076 - val_accuracy: 0.3269\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8058 - accuracy: 0.2798 - val_loss: 1.7006 - val_accuracy: 0.3625\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.8302 - accuracy: 0.2569 - val_loss: 1.6984 - val_accuracy: 0.3625\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.8050 - accuracy: 0.2618 - val_loss: 1.7013 - val_accuracy: 0.3625\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.8081 - accuracy: 0.2775 - val_loss: 1.6999 - val_accuracy: 0.3398\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8016 - accuracy: 0.2713 - val_loss: 1.7003 - val_accuracy: 0.3625\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8047 - accuracy: 0.2842 - val_loss: 1.6985 - val_accuracy: 0.3592\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7918 - accuracy: 0.2881 - val_loss: 1.6946 - val_accuracy: 0.3528\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.8040 - accuracy: 0.2847 - val_loss: 1.6966 - val_accuracy: 0.3592\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7927 - accuracy: 0.3019 - val_loss: 1.6920 - val_accuracy: 0.3592\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7966 - accuracy: 0.2880 - val_loss: 1.6910 - val_accuracy: 0.3495\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7665 - accuracy: 0.2927 - val_loss: 1.6878 - val_accuracy: 0.3430\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7857 - accuracy: 0.3040 - val_loss: 1.6862 - val_accuracy: 0.3398\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8006 - accuracy: 0.2806 - val_loss: 1.6892 - val_accuracy: 0.3689\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7695 - accuracy: 0.3132 - val_loss: 1.6832 - val_accuracy: 0.3689\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8168 - accuracy: 0.2867 - val_loss: 1.6809 - val_accuracy: 0.3463\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7578 - accuracy: 0.3149 - val_loss: 1.6802 - val_accuracy: 0.3495\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7736 - accuracy: 0.2940 - val_loss: 1.6891 - val_accuracy: 0.3657\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7868 - accuracy: 0.2865 - val_loss: 1.6745 - val_accuracy: 0.3463\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7662 - accuracy: 0.3123 - val_loss: 1.6753 - val_accuracy: 0.3528\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7618 - accuracy: 0.3028 - val_loss: 1.6766 - val_accuracy: 0.3689\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7426 - accuracy: 0.3203 - val_loss: 1.6671 - val_accuracy: 0.3722\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7911 - accuracy: 0.2673 - val_loss: 1.6657 - val_accuracy: 0.3851\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7392 - accuracy: 0.3067 - val_loss: 1.6676 - val_accuracy: 0.3786\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7629 - accuracy: 0.2984 - val_loss: 1.6642 - val_accuracy: 0.3560\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7375 - accuracy: 0.2980 - val_loss: 1.6614 - val_accuracy: 0.3722\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7614 - accuracy: 0.3258 - val_loss: 1.6496 - val_accuracy: 0.3722\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7752 - accuracy: 0.2877 - val_loss: 1.6455 - val_accuracy: 0.3851\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7619 - accuracy: 0.3086 - val_loss: 1.6458 - val_accuracy: 0.3689\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7406 - accuracy: 0.3295 - val_loss: 1.6569 - val_accuracy: 0.4013\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7471 - accuracy: 0.3011 - val_loss: 1.6472 - val_accuracy: 0.3851\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7626 - accuracy: 0.3240 - val_loss: 1.6426 - val_accuracy: 0.3657\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7119 - accuracy: 0.3175 - val_loss: 1.6483 - val_accuracy: 0.3819\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7223 - accuracy: 0.3082 - val_loss: 1.6427 - val_accuracy: 0.3754\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7690 - accuracy: 0.3210 - val_loss: 1.6416 - val_accuracy: 0.3722\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7406 - accuracy: 0.3328 - val_loss: 1.6453 - val_accuracy: 0.3592\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7687 - accuracy: 0.3007 - val_loss: 1.6416 - val_accuracy: 0.3625\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7481 - accuracy: 0.2995 - val_loss: 1.6432 - val_accuracy: 0.3722\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7533 - accuracy: 0.2948 - val_loss: 1.6536 - val_accuracy: 0.3819\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7615 - accuracy: 0.2946 - val_loss: 1.6448 - val_accuracy: 0.3689\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7142 - accuracy: 0.3293 - val_loss: 1.6386 - val_accuracy: 0.3689\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7232 - accuracy: 0.3215 - val_loss: 1.6350 - val_accuracy: 0.3851\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7167 - accuracy: 0.3341 - val_loss: 1.6297 - val_accuracy: 0.3819\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7149 - accuracy: 0.3312 - val_loss: 1.6241 - val_accuracy: 0.3819\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7160 - accuracy: 0.3240 - val_loss: 1.6334 - val_accuracy: 0.3786\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.7358 - accuracy: 0.3128 - val_loss: 1.6273 - val_accuracy: 0.3883\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7459 - accuracy: 0.3258 - val_loss: 1.6305 - val_accuracy: 0.3851\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7201 - accuracy: 0.3380 - val_loss: 1.6206 - val_accuracy: 0.3851\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7479 - accuracy: 0.3240 - val_loss: 1.6175 - val_accuracy: 0.3948\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7228 - accuracy: 0.3331 - val_loss: 1.6235 - val_accuracy: 0.3883\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7081 - accuracy: 0.3336 - val_loss: 1.6173 - val_accuracy: 0.3948\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7022 - accuracy: 0.3369 - val_loss: 1.6186 - val_accuracy: 0.3948\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7151 - accuracy: 0.3300 - val_loss: 1.6080 - val_accuracy: 0.3916\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7331 - accuracy: 0.3167 - val_loss: 1.6116 - val_accuracy: 0.4175\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7298 - accuracy: 0.3126 - val_loss: 1.6061 - val_accuracy: 0.4045\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7197 - accuracy: 0.3354 - val_loss: 1.6070 - val_accuracy: 0.4013\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7022 - accuracy: 0.3281 - val_loss: 1.6037 - val_accuracy: 0.4045\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6820 - accuracy: 0.3352 - val_loss: 1.6051 - val_accuracy: 0.4078\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7176 - accuracy: 0.3268 - val_loss: 1.6041 - val_accuracy: 0.4013\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6930 - accuracy: 0.3353 - val_loss: 1.6019 - val_accuracy: 0.4045\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7093 - accuracy: 0.3348 - val_loss: 1.6000 - val_accuracy: 0.4013\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6981 - accuracy: 0.3351 - val_loss: 1.5980 - val_accuracy: 0.4078\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7064 - accuracy: 0.3407 - val_loss: 1.6074 - val_accuracy: 0.4110\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6748 - accuracy: 0.3451 - val_loss: 1.5977 - val_accuracy: 0.4175\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7106 - accuracy: 0.3396 - val_loss: 1.5865 - val_accuracy: 0.4175\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6675 - accuracy: 0.3505 - val_loss: 1.5919 - val_accuracy: 0.4207\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6838 - accuracy: 0.3394 - val_loss: 1.5981 - val_accuracy: 0.4045\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6807 - accuracy: 0.3487 - val_loss: 1.5900 - val_accuracy: 0.4110\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6982 - accuracy: 0.3529 - val_loss: 1.5799 - val_accuracy: 0.4175\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6610 - accuracy: 0.3746 - val_loss: 1.5788 - val_accuracy: 0.4239\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6669 - accuracy: 0.3705 - val_loss: 1.5748 - val_accuracy: 0.4369\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7091 - accuracy: 0.3411 - val_loss: 1.5729 - val_accuracy: 0.4207\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6834 - accuracy: 0.3482 - val_loss: 1.5775 - val_accuracy: 0.4239\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6817 - accuracy: 0.3477 - val_loss: 1.5727 - val_accuracy: 0.4142\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6780 - accuracy: 0.3553 - val_loss: 1.5692 - val_accuracy: 0.4175\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6711 - accuracy: 0.3396 - val_loss: 1.5630 - val_accuracy: 0.4304\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6665 - accuracy: 0.3572 - val_loss: 1.5634 - val_accuracy: 0.4466\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6464 - accuracy: 0.3600 - val_loss: 1.5576 - val_accuracy: 0.4563\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6469 - accuracy: 0.3806 - val_loss: 1.5602 - val_accuracy: 0.4434\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.6799 - accuracy: 0.3615 - val_loss: 1.5524 - val_accuracy: 0.4369\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6351 - accuracy: 0.3694 - val_loss: 1.5604 - val_accuracy: 0.4369\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6629 - accuracy: 0.3618 - val_loss: 1.5580 - val_accuracy: 0.4272\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.6394 - accuracy: 0.3849 - val_loss: 1.5574 - val_accuracy: 0.4401\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6550 - accuracy: 0.3584 - val_loss: 1.5598 - val_accuracy: 0.4434\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6441 - accuracy: 0.3594 - val_loss: 1.5456 - val_accuracy: 0.4466\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6286 - accuracy: 0.3579 - val_loss: 1.5465 - val_accuracy: 0.4563\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6412 - accuracy: 0.3609 - val_loss: 1.5320 - val_accuracy: 0.4434\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6248 - accuracy: 0.3902 - val_loss: 1.5348 - val_accuracy: 0.4563\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6490 - accuracy: 0.3574 - val_loss: 1.5279 - val_accuracy: 0.4466\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6482 - accuracy: 0.3583 - val_loss: 1.5311 - val_accuracy: 0.4401\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6296 - accuracy: 0.3766 - val_loss: 1.5306 - val_accuracy: 0.4498\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6513 - accuracy: 0.3707 - val_loss: 1.5263 - val_accuracy: 0.4466\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6074 - accuracy: 0.3766 - val_loss: 1.5234 - val_accuracy: 0.4660\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6430 - accuracy: 0.3544 - val_loss: 1.5285 - val_accuracy: 0.4531\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6164 - accuracy: 0.3816 - val_loss: 1.5254 - val_accuracy: 0.4595\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6249 - accuracy: 0.3944 - val_loss: 1.5245 - val_accuracy: 0.4595\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6547 - accuracy: 0.3643 - val_loss: 1.5192 - val_accuracy: 0.4595\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6412 - accuracy: 0.3882 - val_loss: 1.5167 - val_accuracy: 0.4498\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6134 - accuracy: 0.3940 - val_loss: 1.5264 - val_accuracy: 0.4466\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6053 - accuracy: 0.3930 - val_loss: 1.5153 - val_accuracy: 0.4563\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6062 - accuracy: 0.3960 - val_loss: 1.5116 - val_accuracy: 0.4693\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6027 - accuracy: 0.3741 - val_loss: 1.5086 - val_accuracy: 0.4595\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6089 - accuracy: 0.3808 - val_loss: 1.5105 - val_accuracy: 0.4498\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6233 - accuracy: 0.3718 - val_loss: 1.5033 - val_accuracy: 0.4434\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6003 - accuracy: 0.3882 - val_loss: 1.5064 - val_accuracy: 0.4563\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6159 - accuracy: 0.3893 - val_loss: 1.5001 - val_accuracy: 0.4660\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5921 - accuracy: 0.3945 - val_loss: 1.4939 - val_accuracy: 0.4628\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.5633 - accuracy: 0.4086 - val_loss: 1.4863 - val_accuracy: 0.4498\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5895 - accuracy: 0.3873 - val_loss: 1.4856 - val_accuracy: 0.4563\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5910 - accuracy: 0.3917 - val_loss: 1.4839 - val_accuracy: 0.4595\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.6288 - accuracy: 0.3828 - val_loss: 1.4876 - val_accuracy: 0.4757\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5682 - accuracy: 0.4040 - val_loss: 1.4711 - val_accuracy: 0.4693\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5957 - accuracy: 0.3855 - val_loss: 1.4687 - val_accuracy: 0.4725\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5684 - accuracy: 0.4173 - val_loss: 1.4728 - val_accuracy: 0.4693\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5568 - accuracy: 0.4043 - val_loss: 1.4735 - val_accuracy: 0.4660\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5593 - accuracy: 0.4089 - val_loss: 1.4679 - val_accuracy: 0.4725\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5784 - accuracy: 0.4008 - val_loss: 1.4662 - val_accuracy: 0.4660\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5721 - accuracy: 0.3902 - val_loss: 1.4580 - val_accuracy: 0.4822\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5848 - accuracy: 0.3843 - val_loss: 1.4543 - val_accuracy: 0.4757\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5912 - accuracy: 0.4026 - val_loss: 1.4564 - val_accuracy: 0.4757\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5649 - accuracy: 0.4022 - val_loss: 1.4664 - val_accuracy: 0.4693\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5573 - accuracy: 0.4296 - val_loss: 1.4634 - val_accuracy: 0.4854\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5768 - accuracy: 0.3878 - val_loss: 1.4503 - val_accuracy: 0.4660\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5219 - accuracy: 0.4422 - val_loss: 1.4432 - val_accuracy: 0.4790\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5675 - accuracy: 0.3970 - val_loss: 1.4460 - val_accuracy: 0.4951\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.5531 - accuracy: 0.4076 - val_loss: 1.4415 - val_accuracy: 0.4693\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5462 - accuracy: 0.4231 - val_loss: 1.4530 - val_accuracy: 0.4790\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5420 - accuracy: 0.4318 - val_loss: 1.4416 - val_accuracy: 0.4822\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5521 - accuracy: 0.4228 - val_loss: 1.4495 - val_accuracy: 0.4854\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5438 - accuracy: 0.4135 - val_loss: 1.4387 - val_accuracy: 0.4693\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5390 - accuracy: 0.4243 - val_loss: 1.4407 - val_accuracy: 0.4790\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5726 - accuracy: 0.3932 - val_loss: 1.4368 - val_accuracy: 0.4984\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5383 - accuracy: 0.4178 - val_loss: 1.4328 - val_accuracy: 0.4887\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5335 - accuracy: 0.4303 - val_loss: 1.4417 - val_accuracy: 0.4854\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5388 - accuracy: 0.4324 - val_loss: 1.4218 - val_accuracy: 0.4919\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5333 - accuracy: 0.4146 - val_loss: 1.4229 - val_accuracy: 0.4951\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5234 - accuracy: 0.4104 - val_loss: 1.4233 - val_accuracy: 0.4919\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5287 - accuracy: 0.4326 - val_loss: 1.4208 - val_accuracy: 0.4822\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5144 - accuracy: 0.4286 - val_loss: 1.4227 - val_accuracy: 0.5049\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5203 - accuracy: 0.4281 - val_loss: 1.4141 - val_accuracy: 0.5016\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5263 - accuracy: 0.4322 - val_loss: 1.4152 - val_accuracy: 0.5016\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5194 - accuracy: 0.4020 - val_loss: 1.4145 - val_accuracy: 0.4951\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.5261 - accuracy: 0.4140 - val_loss: 1.4058 - val_accuracy: 0.5049\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4873 - accuracy: 0.4288 - val_loss: 1.4053 - val_accuracy: 0.5113\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4910 - accuracy: 0.4476 - val_loss: 1.3986 - val_accuracy: 0.5113\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4953 - accuracy: 0.4406 - val_loss: 1.4047 - val_accuracy: 0.5113\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4989 - accuracy: 0.4259 - val_loss: 1.4007 - val_accuracy: 0.5243\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5208 - accuracy: 0.4361 - val_loss: 1.4068 - val_accuracy: 0.5178\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5488 - accuracy: 0.4097 - val_loss: 1.4209 - val_accuracy: 0.5210\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4627 - accuracy: 0.4509 - val_loss: 1.4085 - val_accuracy: 0.5016\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5149 - accuracy: 0.4393 - val_loss: 1.3946 - val_accuracy: 0.5113\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4940 - accuracy: 0.4334 - val_loss: 1.3814 - val_accuracy: 0.5146\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5366 - accuracy: 0.4223 - val_loss: 1.3809 - val_accuracy: 0.5146\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4728 - accuracy: 0.4634 - val_loss: 1.3820 - val_accuracy: 0.4951\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4805 - accuracy: 0.4424 - val_loss: 1.3848 - val_accuracy: 0.5146\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.4950 - accuracy: 0.4451 - val_loss: 1.3838 - val_accuracy: 0.5243\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4643 - accuracy: 0.4604 - val_loss: 1.3761 - val_accuracy: 0.5210\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4788 - accuracy: 0.4338 - val_loss: 1.3841 - val_accuracy: 0.5275\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4653 - accuracy: 0.4492 - val_loss: 1.3746 - val_accuracy: 0.5178\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4718 - accuracy: 0.4547 - val_loss: 1.3675 - val_accuracy: 0.5178\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4623 - accuracy: 0.4445 - val_loss: 1.3607 - val_accuracy: 0.5210\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4575 - accuracy: 0.4609 - val_loss: 1.3674 - val_accuracy: 0.5340\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4622 - accuracy: 0.4510 - val_loss: 1.3609 - val_accuracy: 0.5113\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4641 - accuracy: 0.4272 - val_loss: 1.3550 - val_accuracy: 0.5307\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4462 - accuracy: 0.4557 - val_loss: 1.3476 - val_accuracy: 0.5243\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4655 - accuracy: 0.4588 - val_loss: 1.3485 - val_accuracy: 0.5275\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4452 - accuracy: 0.4594 - val_loss: 1.3460 - val_accuracy: 0.5307\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4184 - accuracy: 0.4675 - val_loss: 1.3478 - val_accuracy: 0.5437\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4490 - accuracy: 0.4561 - val_loss: 1.3440 - val_accuracy: 0.5437\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4363 - accuracy: 0.4653 - val_loss: 1.3412 - val_accuracy: 0.5372\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4611 - accuracy: 0.4580 - val_loss: 1.3365 - val_accuracy: 0.5534\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4199 - accuracy: 0.4754 - val_loss: 1.3393 - val_accuracy: 0.5469\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4335 - accuracy: 0.4582 - val_loss: 1.3395 - val_accuracy: 0.5275\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4116 - accuracy: 0.4668 - val_loss: 1.3381 - val_accuracy: 0.5275\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4536 - accuracy: 0.4738 - val_loss: 1.3363 - val_accuracy: 0.5307\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3847 - accuracy: 0.4881 - val_loss: 1.3285 - val_accuracy: 0.5340\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4247 - accuracy: 0.4708 - val_loss: 1.3263 - val_accuracy: 0.5405\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4479 - accuracy: 0.4427 - val_loss: 1.3223 - val_accuracy: 0.5372\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4188 - accuracy: 0.4749 - val_loss: 1.3322 - val_accuracy: 0.5340\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4204 - accuracy: 0.4720 - val_loss: 1.3296 - val_accuracy: 0.5340\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.4162 - accuracy: 0.4620 - val_loss: 1.3185 - val_accuracy: 0.5372\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4308 - accuracy: 0.4568 - val_loss: 1.3128 - val_accuracy: 0.5502\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3914 - accuracy: 0.4898 - val_loss: 1.3114 - val_accuracy: 0.5405\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4116 - accuracy: 0.4705 - val_loss: 1.3118 - val_accuracy: 0.5340\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3988 - accuracy: 0.4880 - val_loss: 1.3154 - val_accuracy: 0.5437\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4172 - accuracy: 0.4863 - val_loss: 1.3202 - val_accuracy: 0.5275\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.4211 - accuracy: 0.4549 - val_loss: 1.3139 - val_accuracy: 0.5534\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3949 - accuracy: 0.4831 - val_loss: 1.3138 - val_accuracy: 0.5566\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3935 - accuracy: 0.4901 - val_loss: 1.3079 - val_accuracy: 0.5405\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.4017 - accuracy: 0.4849 - val_loss: 1.2970 - val_accuracy: 0.5437\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3999 - accuracy: 0.4756 - val_loss: 1.3004 - val_accuracy: 0.5599\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3820 - accuracy: 0.4938 - val_loss: 1.2841 - val_accuracy: 0.5469\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3769 - accuracy: 0.4882 - val_loss: 1.2913 - val_accuracy: 0.5502\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3631 - accuracy: 0.4920 - val_loss: 1.3011 - val_accuracy: 0.5566\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4083 - accuracy: 0.4753 - val_loss: 1.2976 - val_accuracy: 0.5469\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3981 - accuracy: 0.4764 - val_loss: 1.2944 - val_accuracy: 0.5566\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3352 - accuracy: 0.5115 - val_loss: 1.2867 - val_accuracy: 0.5599\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3613 - accuracy: 0.4938 - val_loss: 1.2835 - val_accuracy: 0.5469\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3848 - accuracy: 0.4872 - val_loss: 1.2844 - val_accuracy: 0.5566\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3362 - accuracy: 0.5342 - val_loss: 1.2813 - val_accuracy: 0.5372\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3255 - accuracy: 0.5102 - val_loss: 1.2773 - val_accuracy: 0.5599\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3435 - accuracy: 0.5316 - val_loss: 1.2729 - val_accuracy: 0.5599\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3849 - accuracy: 0.4784 - val_loss: 1.2744 - val_accuracy: 0.5534\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3519 - accuracy: 0.4865 - val_loss: 1.2715 - val_accuracy: 0.5761\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3324 - accuracy: 0.5032 - val_loss: 1.2654 - val_accuracy: 0.5696\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3720 - accuracy: 0.4851 - val_loss: 1.2575 - val_accuracy: 0.5696\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3491 - accuracy: 0.4962 - val_loss: 1.2716 - val_accuracy: 0.5793\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3436 - accuracy: 0.4934 - val_loss: 1.2614 - val_accuracy: 0.5599\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3649 - accuracy: 0.4930 - val_loss: 1.2668 - val_accuracy: 0.5825\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3321 - accuracy: 0.5094 - val_loss: 1.2709 - val_accuracy: 0.5631\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3162 - accuracy: 0.5155 - val_loss: 1.2738 - val_accuracy: 0.5761\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3640 - accuracy: 0.4789 - val_loss: 1.2657 - val_accuracy: 0.5631\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3268 - accuracy: 0.5015 - val_loss: 1.2592 - val_accuracy: 0.5728\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3079 - accuracy: 0.5213 - val_loss: 1.2562 - val_accuracy: 0.5599\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2997 - accuracy: 0.5223 - val_loss: 1.2519 - val_accuracy: 0.5566\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.3167 - accuracy: 0.4977 - val_loss: 1.2485 - val_accuracy: 0.5696\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3251 - accuracy: 0.5214 - val_loss: 1.2546 - val_accuracy: 0.5761\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3407 - accuracy: 0.5007 - val_loss: 1.2573 - val_accuracy: 0.5566\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3586 - accuracy: 0.4970 - val_loss: 1.2734 - val_accuracy: 0.5599\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3083 - accuracy: 0.5260 - val_loss: 1.2746 - val_accuracy: 0.5405\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3317 - accuracy: 0.5027 - val_loss: 1.2607 - val_accuracy: 0.5534\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2977 - accuracy: 0.5221 - val_loss: 1.2524 - val_accuracy: 0.5534\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3351 - accuracy: 0.5077 - val_loss: 1.2528 - val_accuracy: 0.5372\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3088 - accuracy: 0.5267 - val_loss: 1.2383 - val_accuracy: 0.5566\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2906 - accuracy: 0.5379 - val_loss: 1.2330 - val_accuracy: 0.5631\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3407 - accuracy: 0.5045 - val_loss: 1.2349 - val_accuracy: 0.5793\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2863 - accuracy: 0.5197 - val_loss: 1.2327 - val_accuracy: 0.5761\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2904 - accuracy: 0.5337 - val_loss: 1.2333 - val_accuracy: 0.5631\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3105 - accuracy: 0.5341 - val_loss: 1.2313 - val_accuracy: 0.5502\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3123 - accuracy: 0.5113 - val_loss: 1.2255 - val_accuracy: 0.5793\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3004 - accuracy: 0.5126 - val_loss: 1.2263 - val_accuracy: 0.5858\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3036 - accuracy: 0.5060 - val_loss: 1.2245 - val_accuracy: 0.5696\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2851 - accuracy: 0.5170 - val_loss: 1.2310 - val_accuracy: 0.5663\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3075 - accuracy: 0.5413 - val_loss: 1.2308 - val_accuracy: 0.5761\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2730 - accuracy: 0.5330 - val_loss: 1.2270 - val_accuracy: 0.5987\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2623 - accuracy: 0.5232 - val_loss: 1.2216 - val_accuracy: 0.5696\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2540 - accuracy: 0.5336 - val_loss: 1.2164 - val_accuracy: 0.5696\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2230 - accuracy: 0.5514 - val_loss: 1.2244 - val_accuracy: 0.5922\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2418 - accuracy: 0.5570 - val_loss: 1.2179 - val_accuracy: 0.5825\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2876 - accuracy: 0.5106 - val_loss: 1.2142 - val_accuracy: 0.5793\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.2635 - accuracy: 0.5244 - val_loss: 1.2160 - val_accuracy: 0.5728\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2676 - accuracy: 0.5307 - val_loss: 1.2135 - val_accuracy: 0.5858\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3272 - accuracy: 0.5213 - val_loss: 1.2081 - val_accuracy: 0.5922\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2667 - accuracy: 0.5405 - val_loss: 1.2085 - val_accuracy: 0.5922\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2842 - accuracy: 0.5319 - val_loss: 1.2062 - val_accuracy: 0.5728\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2655 - accuracy: 0.5329 - val_loss: 1.2024 - val_accuracy: 0.5761\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2811 - accuracy: 0.5499 - val_loss: 1.2018 - val_accuracy: 0.5761\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2601 - accuracy: 0.5407 - val_loss: 1.1950 - val_accuracy: 0.5696\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2440 - accuracy: 0.5492 - val_loss: 1.2005 - val_accuracy: 0.5858\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2861 - accuracy: 0.5135 - val_loss: 1.2115 - val_accuracy: 0.5663\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3000 - accuracy: 0.5279 - val_loss: 1.2059 - val_accuracy: 0.5793\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2635 - accuracy: 0.5446 - val_loss: 1.2016 - val_accuracy: 0.5922\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2628 - accuracy: 0.5434 - val_loss: 1.2026 - val_accuracy: 0.5858\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2413 - accuracy: 0.5383 - val_loss: 1.2032 - val_accuracy: 0.5922\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2640 - accuracy: 0.5217 - val_loss: 1.2053 - val_accuracy: 0.5825\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2227 - accuracy: 0.5669 - val_loss: 1.2054 - val_accuracy: 0.5987\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1907 - accuracy: 0.5556 - val_loss: 1.1891 - val_accuracy: 0.5955\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2250 - accuracy: 0.5677 - val_loss: 1.1798 - val_accuracy: 0.5825\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1914 - accuracy: 0.5542 - val_loss: 1.1836 - val_accuracy: 0.5955\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1857 - accuracy: 0.5762 - val_loss: 1.1766 - val_accuracy: 0.5890\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.2598 - accuracy: 0.5318 - val_loss: 1.1781 - val_accuracy: 0.6052\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1656 - accuracy: 0.5840 - val_loss: 1.1756 - val_accuracy: 0.5922\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2170 - accuracy: 0.5551 - val_loss: 1.1677 - val_accuracy: 0.6052\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2133 - accuracy: 0.5652 - val_loss: 1.1685 - val_accuracy: 0.5955\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1827 - accuracy: 0.5707 - val_loss: 1.1693 - val_accuracy: 0.6019\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1978 - accuracy: 0.5568 - val_loss: 1.1666 - val_accuracy: 0.5922\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1899 - accuracy: 0.5655 - val_loss: 1.1697 - val_accuracy: 0.5987\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1926 - accuracy: 0.5692 - val_loss: 1.1709 - val_accuracy: 0.5922\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1868 - accuracy: 0.5644 - val_loss: 1.1662 - val_accuracy: 0.5987\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2000 - accuracy: 0.5652 - val_loss: 1.1596 - val_accuracy: 0.6052\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1786 - accuracy: 0.5596 - val_loss: 1.1574 - val_accuracy: 0.5825\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1426 - accuracy: 0.5882 - val_loss: 1.1546 - val_accuracy: 0.6019\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1829 - accuracy: 0.5673 - val_loss: 1.1473 - val_accuracy: 0.5987\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.1674 - accuracy: 0.5713 - val_loss: 1.1532 - val_accuracy: 0.5890\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2069 - accuracy: 0.5560 - val_loss: 1.1553 - val_accuracy: 0.6019\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1401 - accuracy: 0.5891 - val_loss: 1.1503 - val_accuracy: 0.5987\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1674 - accuracy: 0.5656 - val_loss: 1.1407 - val_accuracy: 0.6181\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1777 - accuracy: 0.5602 - val_loss: 1.1353 - val_accuracy: 0.6084\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1900 - accuracy: 0.5647 - val_loss: 1.1468 - val_accuracy: 0.6052\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1282 - accuracy: 0.6038 - val_loss: 1.1560 - val_accuracy: 0.5987\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1846 - accuracy: 0.5614 - val_loss: 1.1586 - val_accuracy: 0.5858\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1509 - accuracy: 0.5868 - val_loss: 1.1570 - val_accuracy: 0.6019\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1866 - accuracy: 0.5534 - val_loss: 1.1542 - val_accuracy: 0.5987\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1542 - accuracy: 0.5958 - val_loss: 1.1485 - val_accuracy: 0.5922\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1620 - accuracy: 0.5889 - val_loss: 1.1328 - val_accuracy: 0.6052\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1644 - accuracy: 0.5750 - val_loss: 1.1344 - val_accuracy: 0.5890\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1417 - accuracy: 0.5778 - val_loss: 1.1375 - val_accuracy: 0.5955\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1522 - accuracy: 0.5748 - val_loss: 1.1420 - val_accuracy: 0.6084\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1469 - accuracy: 0.5703 - val_loss: 1.1460 - val_accuracy: 0.5858\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1261 - accuracy: 0.5963 - val_loss: 1.1412 - val_accuracy: 0.5825\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0983 - accuracy: 0.6109 - val_loss: 1.1316 - val_accuracy: 0.5987\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1423 - accuracy: 0.5674 - val_loss: 1.1293 - val_accuracy: 0.5955\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1167 - accuracy: 0.5715 - val_loss: 1.1273 - val_accuracy: 0.5955\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1165 - accuracy: 0.5915 - val_loss: 1.1281 - val_accuracy: 0.6084\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1260 - accuracy: 0.5894 - val_loss: 1.1376 - val_accuracy: 0.6019\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0953 - accuracy: 0.6010 - val_loss: 1.1288 - val_accuracy: 0.6181\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0938 - accuracy: 0.6045 - val_loss: 1.1308 - val_accuracy: 0.5825\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1378 - accuracy: 0.5830 - val_loss: 1.1241 - val_accuracy: 0.6246\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1180 - accuracy: 0.5771 - val_loss: 1.1265 - val_accuracy: 0.6117\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1430 - accuracy: 0.5884 - val_loss: 1.1205 - val_accuracy: 0.6149\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0763 - accuracy: 0.5903 - val_loss: 1.1155 - val_accuracy: 0.6117\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.1198 - accuracy: 0.5869 - val_loss: 1.1092 - val_accuracy: 0.6214\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.1243 - accuracy: 0.5929 - val_loss: 1.1371 - val_accuracy: 0.5728\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0877 - accuracy: 0.5807 - val_loss: 1.1326 - val_accuracy: 0.5955\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0758 - accuracy: 0.6055 - val_loss: 1.1241 - val_accuracy: 0.6052\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0934 - accuracy: 0.6109 - val_loss: 1.1324 - val_accuracy: 0.5890\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1262 - accuracy: 0.6022 - val_loss: 1.1189 - val_accuracy: 0.6084\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0885 - accuracy: 0.5971 - val_loss: 1.1240 - val_accuracy: 0.6052\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0897 - accuracy: 0.6073 - val_loss: 1.1265 - val_accuracy: 0.5890\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0647 - accuracy: 0.6081 - val_loss: 1.1122 - val_accuracy: 0.6052\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0938 - accuracy: 0.5940 - val_loss: 1.1075 - val_accuracy: 0.6214\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1072 - accuracy: 0.5943 - val_loss: 1.1149 - val_accuracy: 0.6084\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1263 - accuracy: 0.6043 - val_loss: 1.1117 - val_accuracy: 0.6019\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0644 - accuracy: 0.6242 - val_loss: 1.1138 - val_accuracy: 0.6214\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0412 - accuracy: 0.6253 - val_loss: 1.1264 - val_accuracy: 0.5890\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0803 - accuracy: 0.6090 - val_loss: 1.1159 - val_accuracy: 0.5955\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0840 - accuracy: 0.6024 - val_loss: 1.1035 - val_accuracy: 0.5955\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0653 - accuracy: 0.6208 - val_loss: 1.1005 - val_accuracy: 0.6084\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0484 - accuracy: 0.6178 - val_loss: 1.0952 - val_accuracy: 0.6181\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0740 - accuracy: 0.6073 - val_loss: 1.0920 - val_accuracy: 0.6149\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0177 - accuracy: 0.6065 - val_loss: 1.0872 - val_accuracy: 0.6117\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0153 - accuracy: 0.6123 - val_loss: 1.0825 - val_accuracy: 0.6311\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0346 - accuracy: 0.6338 - val_loss: 1.0754 - val_accuracy: 0.6084\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0833 - accuracy: 0.6008 - val_loss: 1.0819 - val_accuracy: 0.6019\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0247 - accuracy: 0.6333 - val_loss: 1.0849 - val_accuracy: 0.6214\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0804 - accuracy: 0.5918 - val_loss: 1.0838 - val_accuracy: 0.6246\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0464 - accuracy: 0.6366 - val_loss: 1.0851 - val_accuracy: 0.6181\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0449 - accuracy: 0.6164 - val_loss: 1.0886 - val_accuracy: 0.6084\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0339 - accuracy: 0.6085 - val_loss: 1.0836 - val_accuracy: 0.6117\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0679 - accuracy: 0.6294 - val_loss: 1.0788 - val_accuracy: 0.6117\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0539 - accuracy: 0.6325 - val_loss: 1.0765 - val_accuracy: 0.6214\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0275 - accuracy: 0.6239 - val_loss: 1.0802 - val_accuracy: 0.6117\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0387 - accuracy: 0.6315 - val_loss: 1.0796 - val_accuracy: 0.6181\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0171 - accuracy: 0.6174 - val_loss: 1.0927 - val_accuracy: 0.6052\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0209 - accuracy: 0.6285 - val_loss: 1.0961 - val_accuracy: 0.5955\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0370 - accuracy: 0.6063 - val_loss: 1.0965 - val_accuracy: 0.5922\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0589 - accuracy: 0.6064 - val_loss: 1.0820 - val_accuracy: 0.6117\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0267 - accuracy: 0.6278 - val_loss: 1.0811 - val_accuracy: 0.6214\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0108 - accuracy: 0.6274 - val_loss: 1.0830 - val_accuracy: 0.6181\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0027 - accuracy: 0.6402 - val_loss: 1.0706 - val_accuracy: 0.6052\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9965 - accuracy: 0.6385 - val_loss: 1.0692 - val_accuracy: 0.5955\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0417 - accuracy: 0.6069 - val_loss: 1.0697 - val_accuracy: 0.6117\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0103 - accuracy: 0.6182 - val_loss: 1.0712 - val_accuracy: 0.6149\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9876 - accuracy: 0.6353 - val_loss: 1.0841 - val_accuracy: 0.6019\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0418 - accuracy: 0.6092 - val_loss: 1.0869 - val_accuracy: 0.6084\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0017 - accuracy: 0.6095 - val_loss: 1.0833 - val_accuracy: 0.5987\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0262 - accuracy: 0.6365 - val_loss: 1.0742 - val_accuracy: 0.6052\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9899 - accuracy: 0.6174 - val_loss: 1.0843 - val_accuracy: 0.6052\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0217 - accuracy: 0.6033 - val_loss: 1.0662 - val_accuracy: 0.6214\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9679 - accuracy: 0.6530 - val_loss: 1.0595 - val_accuracy: 0.6214\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0004 - accuracy: 0.6264 - val_loss: 1.0606 - val_accuracy: 0.6343\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9832 - accuracy: 0.6483 - val_loss: 1.0568 - val_accuracy: 0.6246\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9893 - accuracy: 0.6444 - val_loss: 1.0705 - val_accuracy: 0.6052\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9853 - accuracy: 0.6225 - val_loss: 1.0619 - val_accuracy: 0.6149\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9609 - accuracy: 0.6678 - val_loss: 1.0704 - val_accuracy: 0.6117\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9861 - accuracy: 0.6436 - val_loss: 1.0821 - val_accuracy: 0.6117\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9878 - accuracy: 0.6543 - val_loss: 1.0629 - val_accuracy: 0.6084\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9625 - accuracy: 0.6565 - val_loss: 1.0582 - val_accuracy: 0.6084\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9599 - accuracy: 0.6478 - val_loss: 1.0541 - val_accuracy: 0.6149\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9925 - accuracy: 0.6230 - val_loss: 1.0529 - val_accuracy: 0.6019\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9976 - accuracy: 0.6354 - val_loss: 1.0541 - val_accuracy: 0.6117\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9405 - accuracy: 0.6568 - val_loss: 1.0598 - val_accuracy: 0.6214\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9755 - accuracy: 0.6685 - val_loss: 1.0487 - val_accuracy: 0.6117\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9634 - accuracy: 0.6351 - val_loss: 1.0582 - val_accuracy: 0.6117\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9526 - accuracy: 0.6630 - val_loss: 1.0475 - val_accuracy: 0.6052\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9628 - accuracy: 0.6524 - val_loss: 1.0387 - val_accuracy: 0.6246\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9488 - accuracy: 0.6681 - val_loss: 1.0449 - val_accuracy: 0.6117\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9605 - accuracy: 0.6473 - val_loss: 1.0390 - val_accuracy: 0.6149\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9800 - accuracy: 0.6463 - val_loss: 1.0419 - val_accuracy: 0.6117\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9325 - accuracy: 0.6431 - val_loss: 1.0519 - val_accuracy: 0.6181\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9309 - accuracy: 0.6562 - val_loss: 1.0583 - val_accuracy: 0.6214\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9365 - accuracy: 0.6436 - val_loss: 1.0527 - val_accuracy: 0.5955\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9675 - accuracy: 0.6495 - val_loss: 1.0464 - val_accuracy: 0.6117\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8920 - accuracy: 0.6730 - val_loss: 1.0515 - val_accuracy: 0.6084\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9356 - accuracy: 0.6491 - val_loss: 1.0499 - val_accuracy: 0.6084\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9454 - accuracy: 0.6632 - val_loss: 1.0564 - val_accuracy: 0.6084\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9444 - accuracy: 0.6488 - val_loss: 1.0534 - val_accuracy: 0.6149\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8927 - accuracy: 0.6848 - val_loss: 1.0504 - val_accuracy: 0.6117\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9435 - accuracy: 0.6591 - val_loss: 1.0566 - val_accuracy: 0.5987\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9163 - accuracy: 0.6643 - val_loss: 1.0407 - val_accuracy: 0.6440\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9443 - accuracy: 0.6603 - val_loss: 1.0389 - val_accuracy: 0.6214\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9217 - accuracy: 0.6806 - val_loss: 1.0287 - val_accuracy: 0.6052\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9386 - accuracy: 0.6536 - val_loss: 1.0287 - val_accuracy: 0.6117\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9024 - accuracy: 0.6839 - val_loss: 1.0338 - val_accuracy: 0.6149\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8923 - accuracy: 0.6863 - val_loss: 1.0510 - val_accuracy: 0.6246\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8968 - accuracy: 0.6625 - val_loss: 1.0305 - val_accuracy: 0.5987\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8769 - accuracy: 0.6952 - val_loss: 1.0255 - val_accuracy: 0.6019\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8723 - accuracy: 0.6799 - val_loss: 1.0297 - val_accuracy: 0.6052\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9023 - accuracy: 0.6568 - val_loss: 1.0331 - val_accuracy: 0.6019\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8860 - accuracy: 0.6782 - val_loss: 1.0251 - val_accuracy: 0.6246\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8984 - accuracy: 0.6756 - val_loss: 1.0303 - val_accuracy: 0.6246\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8854 - accuracy: 0.6594 - val_loss: 1.0138 - val_accuracy: 0.6440\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8851 - accuracy: 0.6718 - val_loss: 1.0183 - val_accuracy: 0.6181\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8655 - accuracy: 0.6876 - val_loss: 1.0259 - val_accuracy: 0.6149\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9054 - accuracy: 0.6555 - val_loss: 1.0275 - val_accuracy: 0.6246\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8794 - accuracy: 0.6829 - val_loss: 1.0348 - val_accuracy: 0.6246\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9107 - accuracy: 0.6753 - val_loss: 1.0274 - val_accuracy: 0.6084\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8638 - accuracy: 0.6926 - val_loss: 1.0285 - val_accuracy: 0.6246\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9079 - accuracy: 0.6600 - val_loss: 1.0246 - val_accuracy: 0.6084\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9222 - accuracy: 0.6488 - val_loss: 1.0078 - val_accuracy: 0.6278\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8612 - accuracy: 0.6972 - val_loss: 1.0137 - val_accuracy: 0.6246\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8736 - accuracy: 0.7032 - val_loss: 1.0204 - val_accuracy: 0.6343\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8559 - accuracy: 0.6986 - val_loss: 1.0101 - val_accuracy: 0.6278\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8695 - accuracy: 0.6761 - val_loss: 1.0130 - val_accuracy: 0.6375\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8759 - accuracy: 0.6773 - val_loss: 1.0202 - val_accuracy: 0.6181\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8430 - accuracy: 0.6885 - val_loss: 1.0370 - val_accuracy: 0.6408\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8884 - accuracy: 0.6893 - val_loss: 1.0196 - val_accuracy: 0.6246\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8851 - accuracy: 0.6801 - val_loss: 1.0161 - val_accuracy: 0.6149\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8716 - accuracy: 0.6877 - val_loss: 1.0165 - val_accuracy: 0.6343\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8367 - accuracy: 0.6974 - val_loss: 1.0286 - val_accuracy: 0.6214\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8849 - accuracy: 0.6804 - val_loss: 1.0250 - val_accuracy: 0.6181\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8736 - accuracy: 0.6795 - val_loss: 1.0189 - val_accuracy: 0.6311\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8397 - accuracy: 0.6845 - val_loss: 1.0224 - val_accuracy: 0.5987\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8642 - accuracy: 0.6867 - val_loss: 1.0215 - val_accuracy: 0.6019\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8183 - accuracy: 0.7018 - val_loss: 1.0174 - val_accuracy: 0.6117\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8686 - accuracy: 0.6835 - val_loss: 1.0132 - val_accuracy: 0.6084\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8553 - accuracy: 0.6943 - val_loss: 1.0168 - val_accuracy: 0.6084\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8632 - accuracy: 0.6828 - val_loss: 1.0118 - val_accuracy: 0.6052\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8965 - accuracy: 0.6650 - val_loss: 1.0288 - val_accuracy: 0.6246\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8579 - accuracy: 0.6846 - val_loss: 1.0239 - val_accuracy: 0.6246\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8594 - accuracy: 0.6871 - val_loss: 1.0077 - val_accuracy: 0.6246\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8386 - accuracy: 0.6941 - val_loss: 1.0258 - val_accuracy: 0.6214\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8491 - accuracy: 0.6940 - val_loss: 1.0231 - val_accuracy: 0.6343\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8228 - accuracy: 0.7078 - val_loss: 1.0009 - val_accuracy: 0.6214\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8448 - accuracy: 0.6950 - val_loss: 0.9924 - val_accuracy: 0.6214\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.8121 - accuracy: 0.7034 - val_loss: 1.0001 - val_accuracy: 0.6311\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8264 - accuracy: 0.6871 - val_loss: 1.0125 - val_accuracy: 0.6278\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8473 - accuracy: 0.6989 - val_loss: 1.0024 - val_accuracy: 0.6246\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8006 - accuracy: 0.7046 - val_loss: 0.9994 - val_accuracy: 0.6408\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7924 - accuracy: 0.7043 - val_loss: 1.0150 - val_accuracy: 0.6214\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8331 - accuracy: 0.6940 - val_loss: 1.0102 - val_accuracy: 0.6149\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8437 - accuracy: 0.7092 - val_loss: 1.0162 - val_accuracy: 0.6117\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8068 - accuracy: 0.7097 - val_loss: 1.0178 - val_accuracy: 0.6246\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7473 - accuracy: 0.7337 - val_loss: 0.9974 - val_accuracy: 0.6117\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7854 - accuracy: 0.7147 - val_loss: 1.0007 - val_accuracy: 0.6278\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8851 - accuracy: 0.6986 - val_loss: 1.0119 - val_accuracy: 0.6149\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8183 - accuracy: 0.7153 - val_loss: 1.0090 - val_accuracy: 0.6117\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8294 - accuracy: 0.7005 - val_loss: 1.0196 - val_accuracy: 0.6149\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7781 - accuracy: 0.7159 - val_loss: 1.0243 - val_accuracy: 0.6278\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7923 - accuracy: 0.6995 - val_loss: 1.0069 - val_accuracy: 0.6278\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8140 - accuracy: 0.7150 - val_loss: 0.9902 - val_accuracy: 0.6278\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7905 - accuracy: 0.7072 - val_loss: 1.0103 - val_accuracy: 0.6149\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7527 - accuracy: 0.7176 - val_loss: 1.0185 - val_accuracy: 0.6181\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8392 - accuracy: 0.7113 - val_loss: 1.0065 - val_accuracy: 0.6343\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7810 - accuracy: 0.7145 - val_loss: 0.9964 - val_accuracy: 0.6214\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8015 - accuracy: 0.7136 - val_loss: 1.0057 - val_accuracy: 0.6214\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7571 - accuracy: 0.7217 - val_loss: 1.0098 - val_accuracy: 0.6181\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7660 - accuracy: 0.7209 - val_loss: 0.9988 - val_accuracy: 0.6052\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7731 - accuracy: 0.7094 - val_loss: 1.0027 - val_accuracy: 0.6181\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7823 - accuracy: 0.7341 - val_loss: 0.9934 - val_accuracy: 0.6149\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7347 - accuracy: 0.7259 - val_loss: 1.0024 - val_accuracy: 0.6181\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7455 - accuracy: 0.7293 - val_loss: 1.0136 - val_accuracy: 0.6084\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7347 - accuracy: 0.7382 - val_loss: 1.0035 - val_accuracy: 0.6246\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7629 - accuracy: 0.7296 - val_loss: 1.0004 - val_accuracy: 0.6472\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7389 - accuracy: 0.7286 - val_loss: 0.9937 - val_accuracy: 0.6343\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8006 - accuracy: 0.7210 - val_loss: 0.9875 - val_accuracy: 0.6505\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7922 - accuracy: 0.7008 - val_loss: 0.9808 - val_accuracy: 0.6408\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7494 - accuracy: 0.7226 - val_loss: 0.9758 - val_accuracy: 0.6343\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7568 - accuracy: 0.7428 - val_loss: 0.9840 - val_accuracy: 0.6602\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7745 - accuracy: 0.7227 - val_loss: 1.0007 - val_accuracy: 0.6278\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7625 - accuracy: 0.7500 - val_loss: 0.9888 - val_accuracy: 0.6214\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7323 - accuracy: 0.7237 - val_loss: 0.9794 - val_accuracy: 0.6278\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7805 - accuracy: 0.7173 - val_loss: 0.9840 - val_accuracy: 0.6181\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7813 - accuracy: 0.7309 - val_loss: 0.9999 - val_accuracy: 0.6505\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7497 - accuracy: 0.7462 - val_loss: 0.9881 - val_accuracy: 0.6505\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7382 - accuracy: 0.7294 - val_loss: 0.9873 - val_accuracy: 0.6278\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7579 - accuracy: 0.7334 - val_loss: 1.0200 - val_accuracy: 0.6278\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7347 - accuracy: 0.7608 - val_loss: 0.9873 - val_accuracy: 0.6246\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7860 - accuracy: 0.7079 - val_loss: 0.9639 - val_accuracy: 0.6472\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7510 - accuracy: 0.7197 - val_loss: 0.9982 - val_accuracy: 0.6278\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7067 - accuracy: 0.7686 - val_loss: 0.9778 - val_accuracy: 0.6181\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7383 - accuracy: 0.7362 - val_loss: 0.9733 - val_accuracy: 0.6246\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7287 - accuracy: 0.7447 - val_loss: 0.9971 - val_accuracy: 0.6278\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7432 - accuracy: 0.7356 - val_loss: 0.9844 - val_accuracy: 0.6181\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7497 - accuracy: 0.7256 - val_loss: 0.9684 - val_accuracy: 0.6214\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7175 - accuracy: 0.7481 - val_loss: 0.9865 - val_accuracy: 0.6278\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6911 - accuracy: 0.7460 - val_loss: 0.9869 - val_accuracy: 0.6019\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7284 - accuracy: 0.7344 - val_loss: 0.9886 - val_accuracy: 0.6246\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6655 - accuracy: 0.7576 - val_loss: 0.9901 - val_accuracy: 0.6278\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6852 - accuracy: 0.7552 - val_loss: 1.0023 - val_accuracy: 0.6311\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7420 - accuracy: 0.7352 - val_loss: 0.9803 - val_accuracy: 0.6343\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7305 - accuracy: 0.7414 - val_loss: 0.9776 - val_accuracy: 0.6375\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7252 - accuracy: 0.7255 - val_loss: 0.9744 - val_accuracy: 0.6375\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6600 - accuracy: 0.7722 - val_loss: 0.9763 - val_accuracy: 0.6311\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6966 - accuracy: 0.7586 - val_loss: 0.9970 - val_accuracy: 0.6343\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7088 - accuracy: 0.7511 - val_loss: 1.0086 - val_accuracy: 0.6181\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7041 - accuracy: 0.7595 - val_loss: 0.9777 - val_accuracy: 0.6408\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7019 - accuracy: 0.7413 - val_loss: 0.9833 - val_accuracy: 0.6472\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7177 - accuracy: 0.7464 - val_loss: 0.9823 - val_accuracy: 0.6472\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7219 - accuracy: 0.7383 - val_loss: 0.9612 - val_accuracy: 0.6375\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7450 - accuracy: 0.7304 - val_loss: 0.9841 - val_accuracy: 0.6278\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7089 - accuracy: 0.7437 - val_loss: 0.9901 - val_accuracy: 0.6214\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7571 - accuracy: 0.7334 - val_loss: 0.9717 - val_accuracy: 0.6440\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7113 - accuracy: 0.7545 - val_loss: 0.9676 - val_accuracy: 0.6440\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7345 - accuracy: 0.7301 - val_loss: 0.9798 - val_accuracy: 0.6375\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6954 - accuracy: 0.7439 - val_loss: 0.9740 - val_accuracy: 0.6311\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.7630 - val_loss: 0.9921 - val_accuracy: 0.6278\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6358 - accuracy: 0.7729 - val_loss: 0.9843 - val_accuracy: 0.6505\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6767 - accuracy: 0.7605 - val_loss: 0.9803 - val_accuracy: 0.6440\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6958 - accuracy: 0.7568 - val_loss: 0.9864 - val_accuracy: 0.6472\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7152 - accuracy: 0.7445 - val_loss: 1.0125 - val_accuracy: 0.6181\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6425 - accuracy: 0.7580 - val_loss: 1.0052 - val_accuracy: 0.6311\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6677 - accuracy: 0.7576 - val_loss: 0.9789 - val_accuracy: 0.6408\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6950 - accuracy: 0.7460 - val_loss: 0.9831 - val_accuracy: 0.6246\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6662 - accuracy: 0.7659 - val_loss: 0.9820 - val_accuracy: 0.6375\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7307 - accuracy: 0.7213 - val_loss: 0.9631 - val_accuracy: 0.6375\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.7639 - val_loss: 0.9797 - val_accuracy: 0.6537\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6509 - accuracy: 0.7719 - val_loss: 0.9690 - val_accuracy: 0.6375\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6435 - accuracy: 0.7592 - val_loss: 0.9713 - val_accuracy: 0.6343\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7040 - accuracy: 0.7432 - val_loss: 0.9774 - val_accuracy: 0.6375\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6554 - accuracy: 0.7783 - val_loss: 0.9705 - val_accuracy: 0.6311\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6502 - accuracy: 0.7766 - val_loss: 0.9745 - val_accuracy: 0.6440\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6274 - accuracy: 0.7736 - val_loss: 0.9615 - val_accuracy: 0.6602\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6788 - accuracy: 0.7654 - val_loss: 0.9677 - val_accuracy: 0.6570\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6395 - accuracy: 0.7863 - val_loss: 0.9838 - val_accuracy: 0.6375\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6917 - accuracy: 0.7544 - val_loss: 0.9706 - val_accuracy: 0.6537\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6422 - accuracy: 0.7718 - val_loss: 0.9821 - val_accuracy: 0.6505\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6412 - accuracy: 0.7605 - val_loss: 0.9801 - val_accuracy: 0.6408\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6396 - accuracy: 0.7762 - val_loss: 0.9696 - val_accuracy: 0.6375\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6543 - accuracy: 0.7661 - val_loss: 0.9840 - val_accuracy: 0.6181\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6292 - accuracy: 0.7854 - val_loss: 0.9661 - val_accuracy: 0.6440\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6413 - accuracy: 0.7743 - val_loss: 0.9538 - val_accuracy: 0.6570\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6599 - accuracy: 0.7699 - val_loss: 0.9637 - val_accuracy: 0.6505\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6042 - accuracy: 0.8001 - val_loss: 0.9538 - val_accuracy: 0.6408\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6135 - accuracy: 0.7764 - val_loss: 0.9715 - val_accuracy: 0.6472\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6520 - accuracy: 0.7699 - val_loss: 0.9566 - val_accuracy: 0.6472\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6599 - accuracy: 0.7575 - val_loss: 0.9484 - val_accuracy: 0.6602\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6361 - accuracy: 0.7646 - val_loss: 0.9400 - val_accuracy: 0.6699\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6232 - accuracy: 0.7788 - val_loss: 0.9461 - val_accuracy: 0.6505\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6514 - accuracy: 0.7624 - val_loss: 0.9753 - val_accuracy: 0.6505\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6264 - accuracy: 0.7907 - val_loss: 0.9777 - val_accuracy: 0.6408\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6470 - accuracy: 0.7559 - val_loss: 0.9767 - val_accuracy: 0.6602\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6245 - accuracy: 0.7917 - val_loss: 0.9840 - val_accuracy: 0.6440\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6255 - accuracy: 0.7670 - val_loss: 0.9771 - val_accuracy: 0.6440\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6072 - accuracy: 0.7756 - val_loss: 0.9909 - val_accuracy: 0.6375\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6180 - accuracy: 0.7906 - val_loss: 0.9818 - val_accuracy: 0.6602\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6342 - accuracy: 0.7723 - val_loss: 0.9900 - val_accuracy: 0.6343\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5884 - accuracy: 0.8096 - val_loss: 0.9712 - val_accuracy: 0.6440\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6084 - accuracy: 0.8047 - val_loss: 0.9751 - val_accuracy: 0.6537\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5885 - accuracy: 0.7947 - val_loss: 0.9655 - val_accuracy: 0.6537\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6097 - accuracy: 0.7975 - val_loss: 0.9652 - val_accuracy: 0.6408\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6324 - accuracy: 0.7706 - val_loss: 0.9673 - val_accuracy: 0.6537\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6029 - accuracy: 0.7772 - val_loss: 0.9675 - val_accuracy: 0.6311\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6056 - accuracy: 0.7797 - val_loss: 0.9581 - val_accuracy: 0.6505\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5999 - accuracy: 0.7727 - val_loss: 0.9593 - val_accuracy: 0.6440\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6231 - accuracy: 0.7676 - val_loss: 0.9946 - val_accuracy: 0.6149\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6187 - accuracy: 0.7653 - val_loss: 0.9933 - val_accuracy: 0.6472\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6029 - accuracy: 0.7925 - val_loss: 0.9846 - val_accuracy: 0.6311\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6026 - accuracy: 0.7961 - val_loss: 0.9700 - val_accuracy: 0.6440\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6431 - accuracy: 0.7576 - val_loss: 0.9656 - val_accuracy: 0.6699\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5840 - accuracy: 0.7951 - val_loss: 0.9579 - val_accuracy: 0.6602\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5949 - accuracy: 0.7890 - val_loss: 0.9431 - val_accuracy: 0.6667\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6477 - accuracy: 0.7723 - val_loss: 0.9696 - val_accuracy: 0.6343\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5544 - accuracy: 0.8142 - val_loss: 0.9675 - val_accuracy: 0.6472\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6105 - accuracy: 0.7705 - val_loss: 0.9631 - val_accuracy: 0.6699\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5834 - accuracy: 0.7932 - val_loss: 0.9797 - val_accuracy: 0.6537\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5771 - accuracy: 0.7774 - val_loss: 0.9831 - val_accuracy: 0.6375\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5930 - accuracy: 0.7791 - val_loss: 0.9593 - val_accuracy: 0.6602\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5918 - accuracy: 0.7764 - val_loss: 0.9560 - val_accuracy: 0.6375\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5656 - accuracy: 0.7975 - val_loss: 0.9752 - val_accuracy: 0.6311\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6048 - accuracy: 0.7809 - val_loss: 0.9433 - val_accuracy: 0.6570\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5642 - accuracy: 0.7942 - val_loss: 0.9607 - val_accuracy: 0.6472\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5755 - accuracy: 0.7957 - val_loss: 0.9643 - val_accuracy: 0.6440\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5866 - accuracy: 0.7880 - val_loss: 0.9666 - val_accuracy: 0.6602\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6155 - accuracy: 0.7778 - val_loss: 0.9538 - val_accuracy: 0.6602\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5678 - accuracy: 0.8009 - val_loss: 0.9630 - val_accuracy: 0.6505\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5834 - accuracy: 0.7826 - val_loss: 0.9676 - val_accuracy: 0.6570\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5644 - accuracy: 0.7955 - val_loss: 0.9418 - val_accuracy: 0.6699\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5888 - accuracy: 0.7989 - val_loss: 0.9424 - val_accuracy: 0.6796\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5665 - accuracy: 0.7982 - val_loss: 0.9639 - val_accuracy: 0.6537\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5816 - accuracy: 0.7807 - val_loss: 0.9584 - val_accuracy: 0.6634\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5393 - accuracy: 0.8179 - val_loss: 0.9598 - val_accuracy: 0.6375\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5620 - accuracy: 0.7974 - val_loss: 0.9577 - val_accuracy: 0.6440\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5773 - accuracy: 0.7809 - val_loss: 0.9608 - val_accuracy: 0.6505\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5035 - accuracy: 0.8234 - val_loss: 0.9781 - val_accuracy: 0.6375\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5900 - accuracy: 0.7754 - val_loss: 0.9750 - val_accuracy: 0.6375\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5301 - accuracy: 0.8200 - val_loss: 0.9453 - val_accuracy: 0.6408\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5704 - accuracy: 0.7994 - val_loss: 0.9385 - val_accuracy: 0.6472\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5603 - accuracy: 0.7994 - val_loss: 0.9301 - val_accuracy: 0.6699\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5279 - accuracy: 0.8330 - val_loss: 0.9345 - val_accuracy: 0.6667\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5512 - accuracy: 0.8067 - val_loss: 0.9383 - val_accuracy: 0.6602\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5392 - accuracy: 0.8061 - val_loss: 0.9243 - val_accuracy: 0.6634\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5171 - accuracy: 0.8126 - val_loss: 0.9383 - val_accuracy: 0.6570\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5465 - accuracy: 0.7897 - val_loss: 0.9516 - val_accuracy: 0.6440\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5506 - accuracy: 0.7951 - val_loss: 0.9328 - val_accuracy: 0.6667\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5184 - accuracy: 0.8111 - val_loss: 0.9382 - val_accuracy: 0.6764\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5540 - accuracy: 0.8052 - val_loss: 0.9344 - val_accuracy: 0.6570\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5455 - accuracy: 0.8188 - val_loss: 0.9502 - val_accuracy: 0.6602\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.8053 - val_loss: 0.9740 - val_accuracy: 0.6764\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5419 - accuracy: 0.8120 - val_loss: 0.9476 - val_accuracy: 0.6570\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5733 - accuracy: 0.7923 - val_loss: 0.9411 - val_accuracy: 0.6537\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5302 - accuracy: 0.8109 - val_loss: 0.9700 - val_accuracy: 0.6505\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5464 - accuracy: 0.8073 - val_loss: 0.9794 - val_accuracy: 0.6408\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5392 - accuracy: 0.8217 - val_loss: 0.9955 - val_accuracy: 0.6375\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5342 - accuracy: 0.8180 - val_loss: 0.9688 - val_accuracy: 0.6505\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5375 - accuracy: 0.8148 - val_loss: 0.9457 - val_accuracy: 0.6505\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5123 - accuracy: 0.8156 - val_loss: 0.9587 - val_accuracy: 0.6440\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5416 - accuracy: 0.8079 - val_loss: 0.9530 - val_accuracy: 0.6958\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5067 - accuracy: 0.8143 - val_loss: 0.9536 - val_accuracy: 0.6472\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5463 - accuracy: 0.8093 - val_loss: 0.9732 - val_accuracy: 0.6570\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5785 - accuracy: 0.7997 - val_loss: 0.9538 - val_accuracy: 0.6731\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5318 - accuracy: 0.8081 - val_loss: 0.9444 - val_accuracy: 0.6440\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5243 - accuracy: 0.8224 - val_loss: 0.9483 - val_accuracy: 0.6634\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5164 - accuracy: 0.8383 - val_loss: 0.9311 - val_accuracy: 0.6861\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5357 - accuracy: 0.8119 - val_loss: 0.9321 - val_accuracy: 0.6699\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5015 - accuracy: 0.8355 - val_loss: 0.9347 - val_accuracy: 0.6699\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5316 - accuracy: 0.8213 - val_loss: 0.9566 - val_accuracy: 0.6634\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5330 - accuracy: 0.8054 - val_loss: 0.9474 - val_accuracy: 0.6634\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5220 - accuracy: 0.8335 - val_loss: 0.9256 - val_accuracy: 0.6796\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5256 - accuracy: 0.8117 - val_loss: 0.9341 - val_accuracy: 0.6667\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4827 - accuracy: 0.8154 - val_loss: 0.9300 - val_accuracy: 0.6667\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5105 - accuracy: 0.8117 - val_loss: 0.9362 - val_accuracy: 0.6699\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4780 - accuracy: 0.8394 - val_loss: 0.9633 - val_accuracy: 0.6634\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5291 - accuracy: 0.8157 - val_loss: 0.9352 - val_accuracy: 0.6505\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5075 - accuracy: 0.8228 - val_loss: 0.9242 - val_accuracy: 0.6667\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4881 - accuracy: 0.8115 - val_loss: 0.9407 - val_accuracy: 0.6634\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5127 - accuracy: 0.8202 - val_loss: 0.9343 - val_accuracy: 0.6731\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4977 - accuracy: 0.8180 - val_loss: 0.9251 - val_accuracy: 0.6828\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.8391 - val_loss: 0.9274 - val_accuracy: 0.6731\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4823 - accuracy: 0.8294 - val_loss: 0.9194 - val_accuracy: 0.6764\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4962 - accuracy: 0.8287 - val_loss: 0.9139 - val_accuracy: 0.6764\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4927 - accuracy: 0.8372 - val_loss: 0.9092 - val_accuracy: 0.6764\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4702 - accuracy: 0.8340 - val_loss: 0.9482 - val_accuracy: 0.6699\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4924 - accuracy: 0.8251 - val_loss: 0.9178 - val_accuracy: 0.6764\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4696 - accuracy: 0.8475 - val_loss: 0.9151 - val_accuracy: 0.6796\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5435 - accuracy: 0.8227 - val_loss: 0.9364 - val_accuracy: 0.6764\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4880 - accuracy: 0.8258 - val_loss: 0.9177 - val_accuracy: 0.6764\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5325 - accuracy: 0.8321 - val_loss: 0.9102 - val_accuracy: 0.6828\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4803 - accuracy: 0.8225 - val_loss: 0.9230 - val_accuracy: 0.6602\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4671 - accuracy: 0.8381 - val_loss: 0.9430 - val_accuracy: 0.6731\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4984 - accuracy: 0.8072 - val_loss: 0.9293 - val_accuracy: 0.6861\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4732 - accuracy: 0.8220 - val_loss: 0.9340 - val_accuracy: 0.6926\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4615 - accuracy: 0.8469 - val_loss: 0.9323 - val_accuracy: 0.6731\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4629 - accuracy: 0.8407 - val_loss: 0.9238 - val_accuracy: 0.6764\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4546 - accuracy: 0.8647 - val_loss: 0.9446 - val_accuracy: 0.6958\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4728 - accuracy: 0.8361 - val_loss: 0.9314 - val_accuracy: 0.6893\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4948 - accuracy: 0.8422 - val_loss: 0.9363 - val_accuracy: 0.6731\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5034 - accuracy: 0.8096 - val_loss: 0.9489 - val_accuracy: 0.6667\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5222 - accuracy: 0.8272 - val_loss: 0.9214 - val_accuracy: 0.6699\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4715 - accuracy: 0.8270 - val_loss: 0.9403 - val_accuracy: 0.6634\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4560 - accuracy: 0.8445 - val_loss: 0.9411 - val_accuracy: 0.6699\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5639 - accuracy: 0.8409 - val_loss: 0.9181 - val_accuracy: 0.6796\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4732 - accuracy: 0.8211 - val_loss: 0.9172 - val_accuracy: 0.6861\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4923 - accuracy: 0.8252 - val_loss: 0.9179 - val_accuracy: 0.6699\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.8537 - val_loss: 0.9280 - val_accuracy: 0.6570\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4540 - accuracy: 0.8364 - val_loss: 0.9247 - val_accuracy: 0.6828\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4354 - accuracy: 0.8522 - val_loss: 0.9376 - val_accuracy: 0.6570\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4679 - accuracy: 0.8227 - val_loss: 0.9288 - val_accuracy: 0.6699\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4892 - accuracy: 0.8202 - val_loss: 0.9281 - val_accuracy: 0.6958\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4408 - accuracy: 0.8546 - val_loss: 0.9496 - val_accuracy: 0.6667\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.8448 - val_loss: 0.9275 - val_accuracy: 0.6634\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4758 - accuracy: 0.8175 - val_loss: 0.9144 - val_accuracy: 0.6699\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4528 - accuracy: 0.8503 - val_loss: 0.9351 - val_accuracy: 0.6699\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4487 - accuracy: 0.8383 - val_loss: 0.9159 - val_accuracy: 0.6796\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.8508 - val_loss: 0.9306 - val_accuracy: 0.6699\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4408 - accuracy: 0.8498 - val_loss: 0.9343 - val_accuracy: 0.6505\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.8482 - val_loss: 0.9395 - val_accuracy: 0.6667\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4227 - accuracy: 0.8461 - val_loss: 0.9574 - val_accuracy: 0.6861\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4764 - accuracy: 0.8237 - val_loss: 0.9496 - val_accuracy: 0.6699\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4529 - accuracy: 0.8498 - val_loss: 0.9337 - val_accuracy: 0.6796\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4483 - accuracy: 0.8433 - val_loss: 0.9337 - val_accuracy: 0.6861\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4223 - accuracy: 0.8392 - val_loss: 0.9475 - val_accuracy: 0.6731\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4480 - accuracy: 0.8549 - val_loss: 0.9511 - val_accuracy: 0.6861\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4134 - accuracy: 0.8584 - val_loss: 0.9732 - val_accuracy: 0.6731\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4624 - accuracy: 0.8305 - val_loss: 0.9424 - val_accuracy: 0.7023\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4337 - accuracy: 0.8417 - val_loss: 0.9392 - val_accuracy: 0.6926\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.8367 - val_loss: 0.9253 - val_accuracy: 0.6828\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4494 - accuracy: 0.8422 - val_loss: 0.9476 - val_accuracy: 0.6570\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4197 - accuracy: 0.8555 - val_loss: 0.9731 - val_accuracy: 0.6570\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4170 - accuracy: 0.8494 - val_loss: 0.9253 - val_accuracy: 0.6861\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3875 - accuracy: 0.8717 - val_loss: 0.9368 - val_accuracy: 0.6731\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4422 - accuracy: 0.8487 - val_loss: 0.9485 - val_accuracy: 0.6667\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4445 - accuracy: 0.8467 - val_loss: 0.9434 - val_accuracy: 0.6570\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4150 - accuracy: 0.8617 - val_loss: 0.9644 - val_accuracy: 0.6667\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4335 - accuracy: 0.8413 - val_loss: 0.9543 - val_accuracy: 0.6926\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4359 - accuracy: 0.8448 - val_loss: 0.9200 - val_accuracy: 0.6861\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4409 - accuracy: 0.8551 - val_loss: 0.9270 - val_accuracy: 0.6764\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4271 - accuracy: 0.8486 - val_loss: 0.9482 - val_accuracy: 0.6731\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3845 - accuracy: 0.8817 - val_loss: 0.9377 - val_accuracy: 0.6861\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4193 - accuracy: 0.8735 - val_loss: 0.9342 - val_accuracy: 0.6731\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4073 - accuracy: 0.8606 - val_loss: 0.9289 - val_accuracy: 0.6828\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4441 - accuracy: 0.8482 - val_loss: 0.9503 - val_accuracy: 0.6926\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3896 - accuracy: 0.8748 - val_loss: 0.9462 - val_accuracy: 0.6796\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4343 - accuracy: 0.8380 - val_loss: 0.9420 - val_accuracy: 0.6796\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4288 - accuracy: 0.8537 - val_loss: 0.9581 - val_accuracy: 0.6667\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4312 - accuracy: 0.8491 - val_loss: 0.9261 - val_accuracy: 0.6699\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4226 - accuracy: 0.8528 - val_loss: 0.9402 - val_accuracy: 0.6570\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4426 - accuracy: 0.8384 - val_loss: 0.9589 - val_accuracy: 0.6537\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4120 - accuracy: 0.8551 - val_loss: 0.9290 - val_accuracy: 0.6731\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4138 - accuracy: 0.8544 - val_loss: 0.9396 - val_accuracy: 0.6861\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4607 - accuracy: 0.8279 - val_loss: 0.9470 - val_accuracy: 0.6828\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3890 - accuracy: 0.8773 - val_loss: 0.9537 - val_accuracy: 0.6505\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3862 - accuracy: 0.8706 - val_loss: 0.9432 - val_accuracy: 0.6731\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4366 - accuracy: 0.8562 - val_loss: 0.9437 - val_accuracy: 0.6828\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4571 - accuracy: 0.8422 - val_loss: 0.9484 - val_accuracy: 0.6828\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3999 - accuracy: 0.8660 - val_loss: 0.9108 - val_accuracy: 0.7152\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3956 - accuracy: 0.8762 - val_loss: 0.9230 - val_accuracy: 0.7023\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3680 - accuracy: 0.8797 - val_loss: 0.9263 - val_accuracy: 0.6861\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4229 - accuracy: 0.8533 - val_loss: 0.9084 - val_accuracy: 0.6861\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3962 - accuracy: 0.8571 - val_loss: 0.9179 - val_accuracy: 0.6731\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3918 - accuracy: 0.8725 - val_loss: 0.9339 - val_accuracy: 0.6828\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4378 - accuracy: 0.8510 - val_loss: 0.9083 - val_accuracy: 0.7055\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3913 - accuracy: 0.8620 - val_loss: 0.9233 - val_accuracy: 0.6893\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.8640 - val_loss: 0.9479 - val_accuracy: 0.6796\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3818 - accuracy: 0.8725 - val_loss: 0.9299 - val_accuracy: 0.6958\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3793 - accuracy: 0.8757 - val_loss: 0.9287 - val_accuracy: 0.6861\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3649 - accuracy: 0.8664 - val_loss: 0.9384 - val_accuracy: 0.6764\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4268 - accuracy: 0.8531 - val_loss: 0.9339 - val_accuracy: 0.6828\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4111 - accuracy: 0.8521 - val_loss: 0.9773 - val_accuracy: 0.6828\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3688 - accuracy: 0.8690 - val_loss: 1.0002 - val_accuracy: 0.6634\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4007 - accuracy: 0.8657 - val_loss: 0.9856 - val_accuracy: 0.6731\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3766 - accuracy: 0.8713 - val_loss: 0.9466 - val_accuracy: 0.6796\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3770 - accuracy: 0.8811 - val_loss: 0.9646 - val_accuracy: 0.6893\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3784 - accuracy: 0.8676 - val_loss: 0.9375 - val_accuracy: 0.6764\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4029 - accuracy: 0.8595 - val_loss: 0.9505 - val_accuracy: 0.6731\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3660 - accuracy: 0.8772 - val_loss: 0.9698 - val_accuracy: 0.6796\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4220 - accuracy: 0.8606 - val_loss: 0.9711 - val_accuracy: 0.6796\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3974 - accuracy: 0.8643 - val_loss: 0.9473 - val_accuracy: 0.6828\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4035 - accuracy: 0.8622 - val_loss: 0.9229 - val_accuracy: 0.6828\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3792 - accuracy: 0.8662 - val_loss: 0.9310 - val_accuracy: 0.6796\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3759 - accuracy: 0.8646 - val_loss: 0.9304 - val_accuracy: 0.6958\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3858 - accuracy: 0.8609 - val_loss: 0.9207 - val_accuracy: 0.6893\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3627 - accuracy: 0.8714 - val_loss: 0.9247 - val_accuracy: 0.6958\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4081 - accuracy: 0.8465 - val_loss: 0.9531 - val_accuracy: 0.6667\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8547 - val_loss: 0.9351 - val_accuracy: 0.6828\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3502 - accuracy: 0.8673 - val_loss: 0.9047 - val_accuracy: 0.7023\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3511 - accuracy: 0.8988 - val_loss: 0.9364 - val_accuracy: 0.6828\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4030 - accuracy: 0.8498 - val_loss: 0.9297 - val_accuracy: 0.6828\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.8751 - val_loss: 0.9104 - val_accuracy: 0.6958\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3794 - accuracy: 0.8744 - val_loss: 0.9149 - val_accuracy: 0.6958\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4060 - accuracy: 0.8578 - val_loss: 0.9063 - val_accuracy: 0.7152\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3844 - accuracy: 0.8640 - val_loss: 0.9248 - val_accuracy: 0.6958\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3883 - accuracy: 0.8637 - val_loss: 0.9504 - val_accuracy: 0.6764\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3556 - accuracy: 0.8793 - val_loss: 0.9247 - val_accuracy: 0.7023\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3836 - accuracy: 0.8708 - val_loss: 0.9296 - val_accuracy: 0.6893\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3308 - accuracy: 0.8903 - val_loss: 0.9490 - val_accuracy: 0.6796\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3604 - accuracy: 0.8628 - val_loss: 0.9385 - val_accuracy: 0.6796\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4054 - accuracy: 0.8615 - val_loss: 0.9236 - val_accuracy: 0.7055\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3526 - accuracy: 0.8817 - val_loss: 0.9222 - val_accuracy: 0.7023\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 0.8939 - val_loss: 0.9200 - val_accuracy: 0.7055\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3709 - accuracy: 0.8753 - val_loss: 0.9078 - val_accuracy: 0.7120\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3849 - accuracy: 0.8630 - val_loss: 0.9049 - val_accuracy: 0.7055\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3686 - accuracy: 0.8811 - val_loss: 0.9247 - val_accuracy: 0.7055\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3523 - accuracy: 0.8849 - val_loss: 0.9055 - val_accuracy: 0.6764\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3522 - accuracy: 0.8756 - val_loss: 0.9065 - val_accuracy: 0.6990\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 0.8875 - val_loss: 0.9219 - val_accuracy: 0.7055\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3464 - accuracy: 0.8700 - val_loss: 0.9290 - val_accuracy: 0.7023\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3376 - accuracy: 0.8914 - val_loss: 0.9340 - val_accuracy: 0.7055\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3328 - accuracy: 0.8879 - val_loss: 0.9318 - val_accuracy: 0.7055\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3223 - accuracy: 0.8955 - val_loss: 0.9362 - val_accuracy: 0.6990\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - accuracy: 0.8488 - val_loss: 0.9320 - val_accuracy: 0.6861\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8824 - val_loss: 0.9104 - val_accuracy: 0.7023\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3251 - accuracy: 0.8898 - val_loss: 0.9146 - val_accuracy: 0.6893\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3243 - accuracy: 0.8938 - val_loss: 0.9244 - val_accuracy: 0.6990\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.8834 - val_loss: 0.9265 - val_accuracy: 0.6958\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3288 - accuracy: 0.8837 - val_loss: 0.9005 - val_accuracy: 0.7184\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3121 - accuracy: 0.8896 - val_loss: 0.9054 - val_accuracy: 0.7055\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2986 - accuracy: 0.8970 - val_loss: 0.9334 - val_accuracy: 0.6958\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3320 - accuracy: 0.8944 - val_loss: 0.9286 - val_accuracy: 0.7023\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3163 - accuracy: 0.8954 - val_loss: 0.9330 - val_accuracy: 0.6990\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3156 - accuracy: 0.8894 - val_loss: 0.9290 - val_accuracy: 0.6958\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3319 - accuracy: 0.8896 - val_loss: 0.9449 - val_accuracy: 0.6764\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4096 - accuracy: 0.8854 - val_loss: 0.9246 - val_accuracy: 0.7184\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3163 - accuracy: 0.9014 - val_loss: 0.9194 - val_accuracy: 0.7023\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3391 - accuracy: 0.8898 - val_loss: 0.9273 - val_accuracy: 0.6667\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2967 - accuracy: 0.9141 - val_loss: 0.9071 - val_accuracy: 0.6926\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3089 - accuracy: 0.8951 - val_loss: 0.9033 - val_accuracy: 0.7152\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3319 - accuracy: 0.8908 - val_loss: 0.9251 - val_accuracy: 0.6958\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3293 - accuracy: 0.8897 - val_loss: 0.9124 - val_accuracy: 0.7023\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3301 - accuracy: 0.8726 - val_loss: 0.9229 - val_accuracy: 0.7087\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3078 - accuracy: 0.8938 - val_loss: 0.9168 - val_accuracy: 0.7152\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3270 - accuracy: 0.9034 - val_loss: 0.9373 - val_accuracy: 0.7055\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3126 - accuracy: 0.8879 - val_loss: 0.9274 - val_accuracy: 0.6990\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8855 - val_loss: 0.9635 - val_accuracy: 0.7087\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3190 - accuracy: 0.8948 - val_loss: 0.9908 - val_accuracy: 0.6796\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3426 - accuracy: 0.8803 - val_loss: 0.9339 - val_accuracy: 0.7055\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3572 - accuracy: 0.8766 - val_loss: 0.9131 - val_accuracy: 0.6958\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3135 - accuracy: 0.8929 - val_loss: 0.9022 - val_accuracy: 0.7184\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3463 - accuracy: 0.8893 - val_loss: 0.9005 - val_accuracy: 0.6958\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3264 - accuracy: 0.8778 - val_loss: 0.9125 - val_accuracy: 0.7087\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3125 - accuracy: 0.8941 - val_loss: 0.9419 - val_accuracy: 0.7023\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2954 - accuracy: 0.9105 - val_loss: 0.9266 - val_accuracy: 0.7055\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3664 - accuracy: 0.8904 - val_loss: 0.9180 - val_accuracy: 0.6990\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.9095 - val_loss: 0.9288 - val_accuracy: 0.6828\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3089 - accuracy: 0.8970 - val_loss: 0.9560 - val_accuracy: 0.6926\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2783 - accuracy: 0.9066 - val_loss: 0.9685 - val_accuracy: 0.6828\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3412 - accuracy: 0.8768 - val_loss: 0.9365 - val_accuracy: 0.7152\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3019 - accuracy: 0.8956 - val_loss: 0.9521 - val_accuracy: 0.7055\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2692 - accuracy: 0.9139 - val_loss: 0.9348 - val_accuracy: 0.7055\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3231 - accuracy: 0.8976 - val_loss: 0.9247 - val_accuracy: 0.6990\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3058 - accuracy: 0.8920 - val_loss: 0.9108 - val_accuracy: 0.7023\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2803 - accuracy: 0.9067 - val_loss: 0.9344 - val_accuracy: 0.6990\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3106 - accuracy: 0.9025 - val_loss: 0.9538 - val_accuracy: 0.6958\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3043 - accuracy: 0.9061 - val_loss: 0.9266 - val_accuracy: 0.7152\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3584 - accuracy: 0.9035 - val_loss: 0.9434 - val_accuracy: 0.6861\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 0.8991 - val_loss: 0.9756 - val_accuracy: 0.6861\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3533 - accuracy: 0.8841 - val_loss: 0.9524 - val_accuracy: 0.6893\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3256 - accuracy: 0.8961 - val_loss: 0.9191 - val_accuracy: 0.6958\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3047 - accuracy: 0.8989 - val_loss: 0.9198 - val_accuracy: 0.6958\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3483 - accuracy: 0.8825 - val_loss: 0.9303 - val_accuracy: 0.7087\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3141 - accuracy: 0.8957 - val_loss: 0.9397 - val_accuracy: 0.6828\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3232 - accuracy: 0.8945 - val_loss: 0.9279 - val_accuracy: 0.6861\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3142 - accuracy: 0.8992 - val_loss: 0.9336 - val_accuracy: 0.6893\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2883 - accuracy: 0.9047 - val_loss: 0.9421 - val_accuracy: 0.7023\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3054 - accuracy: 0.8965 - val_loss: 0.9400 - val_accuracy: 0.7055\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2873 - accuracy: 0.8979 - val_loss: 0.9274 - val_accuracy: 0.7184\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3152 - accuracy: 0.9031 - val_loss: 0.9450 - val_accuracy: 0.7152\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2916 - accuracy: 0.9083 - val_loss: 0.9673 - val_accuracy: 0.7023\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3155 - accuracy: 0.8933 - val_loss: 0.9248 - val_accuracy: 0.6990\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2615 - accuracy: 0.9149 - val_loss: 0.9190 - val_accuracy: 0.7055\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2916 - accuracy: 0.8942 - val_loss: 0.9248 - val_accuracy: 0.7055\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3065 - accuracy: 0.8905 - val_loss: 0.9411 - val_accuracy: 0.7087\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2740 - accuracy: 0.9004 - val_loss: 0.9177 - val_accuracy: 0.7120\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2372 - accuracy: 0.9238 - val_loss: 0.9307 - val_accuracy: 0.6990\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2736 - accuracy: 0.8994 - val_loss: 0.9677 - val_accuracy: 0.6828\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2732 - accuracy: 0.9048 - val_loss: 0.9740 - val_accuracy: 0.6958\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2573 - accuracy: 0.9189 - val_loss: 0.9538 - val_accuracy: 0.7023\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2658 - accuracy: 0.9097 - val_loss: 0.9483 - val_accuracy: 0.6958\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2898 - accuracy: 0.9062 - val_loss: 0.9217 - val_accuracy: 0.7055\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2726 - accuracy: 0.9164 - val_loss: 0.9347 - val_accuracy: 0.7087\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2834 - accuracy: 0.9012 - val_loss: 0.9865 - val_accuracy: 0.7055\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2888 - accuracy: 0.9013 - val_loss: 0.9838 - val_accuracy: 0.7023\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3015 - accuracy: 0.8950 - val_loss: 0.9629 - val_accuracy: 0.7152\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2470 - accuracy: 0.9143 - val_loss: 0.9424 - val_accuracy: 0.7152\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3123 - accuracy: 0.8940 - val_loss: 0.9723 - val_accuracy: 0.7055\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2989 - accuracy: 0.9084 - val_loss: 0.9577 - val_accuracy: 0.6990\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2868 - accuracy: 0.9052 - val_loss: 0.9855 - val_accuracy: 0.6958\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2955 - accuracy: 0.9053 - val_loss: 0.9894 - val_accuracy: 0.6828\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3221 - accuracy: 0.8920 - val_loss: 0.9643 - val_accuracy: 0.6893\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2103 - accuracy: 0.9285 - val_loss: 0.9566 - val_accuracy: 0.6828\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2692 - accuracy: 0.9139 - val_loss: 0.9311 - val_accuracy: 0.6926\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2844 - accuracy: 0.9029 - val_loss: 0.9115 - val_accuracy: 0.7217\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2845 - accuracy: 0.8969 - val_loss: 0.9102 - val_accuracy: 0.7055\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2572 - accuracy: 0.9183 - val_loss: 0.9210 - val_accuracy: 0.7152\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3107 - accuracy: 0.8933 - val_loss: 0.9726 - val_accuracy: 0.6861\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2562 - accuracy: 0.9125 - val_loss: 0.9986 - val_accuracy: 0.7023\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2764 - accuracy: 0.9072 - val_loss: 0.9739 - val_accuracy: 0.6926\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2610 - accuracy: 0.9064 - val_loss: 0.9372 - val_accuracy: 0.7023\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2657 - accuracy: 0.9051 - val_loss: 0.9531 - val_accuracy: 0.6990\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2474 - accuracy: 0.9153 - val_loss: 0.9396 - val_accuracy: 0.7152\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2685 - accuracy: 0.9122 - val_loss: 0.9609 - val_accuracy: 0.7217\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2907 - accuracy: 0.9034 - val_loss: 0.9965 - val_accuracy: 0.6958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "om2osA1gA8Pz",
        "outputId": "0e7c3317-736a-4c5a-9c46-a2ad1d7f49c6"
      },
      "source": [
        "plotter(history)\n",
        "\n",
        "model.summary()\n",
        "result = model.evaluate(X_test,y_test)\n",
        "print(result)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_26 (ModuleWra (None, 153, 64)           704       \n",
            "_________________________________________________________________\n",
            "module_wrapper_27 (ModuleWra (None, 144, 128)          82048     \n",
            "_________________________________________________________________\n",
            "module_wrapper_28 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_29 (ModuleWra (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_30 (ModuleWra (None, 9, 128)            163968    \n",
            "_________________________________________________________________\n",
            "module_wrapper_31 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_32 (ModuleWra (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_33 (ModuleWra (None, 1, 64)             41024     \n",
            "_________________________________________________________________\n",
            "module_wrapper_34 (ModuleWra (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_35 (ModuleWra (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_36 (ModuleWra (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "module_wrapper_37 (ModuleWra (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_38 (ModuleWra (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 306,440\n",
            "Trainable params: 306,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9965 - accuracy: 0.6958\n",
            "[0.9965235590934753, 0.6957928538322449]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e876QkQQhJqgIB0CL1KF1SKa8MuaxexrL2ga99VUVzbz4Ko2HCxLwIiVZqKtNB7aJLQkkB6T87vjzsJKZOQhEwmybyf58mTufeee++5GZh3ThdjDEoppdyXzdUZUEop5VoaCJRSys1pIFBKKTengUAppdycBgKllHJznq7OQEWFhISY8PBwV2dDKaVqlY0bN8YZY0IdHat1gSA8PJwNGza4OhtKKVWriMjh0o5p1ZBSSrk5DQRKKeXmNBAopZSbq3VtBEqpuis7O5vo6GgyMjJcnZVay9fXl7CwMLy8vMp9jgYCpVSNER0dTf369QkPD0dEXJ2dWscYQ3x8PNHR0bRp06bc52nVkFKqxsjIyCA4OFiDQCWJCMHBwRUuUWkgUErVKBoEzk1l/n5uEwj2HE/mjcV7iEvJdHVWlFKqRnFaIBARXxFZJyJbRGSHiLzgIM0tIhIrIpvtP3c4Kz9RJ1N459coTqVmOesWSqlaLiEhgffff79S544bN46EhIRyp3/++ed5/fXXK3WvqubMEkEmcIExpgfQExgjIgMdpPvGGNPT/vOxszJjs5eW8nQhHqVUKcoKBDk5OWWeu2DBAho2bOiMbDmd0wKBsaTYN73sPy77FM6vN8vLc1UOlFI13ZQpU9i/fz89e/bkscceY8WKFQwdOpRLL72ULl26AHD55ZfTp08funbtyowZMwrODQ8PJy4ujkOHDtG5c2fuvPNOunbtykUXXUR6enqZ9928eTMDBw6ke/fuXHHFFZw+fRqAd955hy5dutC9e3euu+46AFauXEnPnj3p2bMnvXr1Ijk5+Zyf26ndR0XEA9gItAPeM8asdZBsgogMA/YCDxljjji4ziRgEkCrVq0qlRctEShVu7wwbwc7jyZV6TW7NG/Ac3/rWurxqVOnsn37djZv3gzAihUriIyMZPv27QXdMWfOnEmjRo1IT0+nX79+TJgwgeDg4CLX2bdvH7Nnz+ajjz7immuu4YcffmDixIml3vemm27i//7v/xg+fDjPPvssL7zwAm+99RZTp07l4MGD+Pj4FFQ7vf7667z33nsMHjyYlJQUfH19z/XP4tzGYmNMrjGmJxAG9BeRbsWSzAPCjTHdgSXA56VcZ4Yxpq8xpm9oqMPJ884qv0SgcUApVRH9+/cv0if/nXfeoUePHgwcOJAjR46wb9++Eue0adOGnj17AtCnTx8OHTpU6vUTExNJSEhg+PDhANx8882sWrUKgO7du3PjjTcya9YsPD2t7+2DBw/m4Ycf5p133iEhIaFg/7molgFlxpgEEVkOjAG2F9ofXyjZx8BrzspDfonAuK52SilVAWV9c69OAQEBBa9XrFjB0qVLWbNmDf7+/owYMcJhn30fH5+C1x4eHmetGirNzz//zKpVq5g3bx4vvfQS27ZtY8qUKYwfP54FCxYwePBgFi1aRKdOnSp1/XzO7DUUKiIN7a/9gAuB3cXSNCu0eSmwy1n5seW3EWgcUEqVon79+mXWuScmJhIUFIS/vz+7d+/mzz//POd7BgYGEhQUxOrVqwH48ssvGT58OHl5eRw5coSRI0fy6quvkpiYSEpKCvv37yciIoInnniCfv36sXv37rPc4eycWSJoBnxubyewAd8aY+aLyIvABmPMXOB+EbkUyAFOAbc4KzOibQRKqbMIDg5m8ODBdOvWjbFjxzJ+/Pgix8eMGcP06dPp3LkzHTt2ZOBARx0hK+7zzz9n8uTJpKWl0bZtWz799FNyc3OZOHEiiYmJGGO4//77adiwIc888wzLly/HZrPRtWtXxo4de873F1PLPhj79u1rKrMwzaq9sdw0cx0/3D2IPq0bOSFnSqlztWvXLjp37uzqbNR6jv6OIrLRGNPXUXq3GVl8pkTg2nwopVRN4zaBwKa9hpRSyiG3CQTaRqCUUo65TSA402tIA4FSShXmdoFA44BSShXlNoFAq4aUUsoxtwkEBSOLNQ4opUpxLtNQA7z11lukpaU5PDZixAgq0/W9OrhNIBBtI1BKnYUzA0FN5jaBQNsIlFJnU3waaoBp06bRr18/unfvznPPPQdAamoq48ePp0ePHnTr1o1vvvmGd955h6NHjzJy5EhGjhxZ5n1mz55NREQE3bp144knngAgNzeXW265hW7duhEREcGbb74JOJ6KuqpVy6RzNYFOQ61ULfPLFDi+rWqv2TQCxk4t9XDxaagXL17Mvn37WLduHcYYLr30UlatWkVsbCzNmzfn559/Bqw5iAIDA3njjTdYvnw5ISEhpd7j6NGjPPHEE2zcuJGgoCAuuugi5syZQ8uWLYmJiWH7dmtezvxppx1NRV3V3KZEIOikc0qpilm8eDGLFy+mV69e9O7dm927d7Nv3z4iIiJYsmQJTzzxBKtXryYwMLDc11y/fj0jRowgNDQUT09PbrzxRlatWkXbtm05cOAA//jHP1i4cCENGjQAHE9FXdXcpkQgBY3FGgmUqhXK+OZeXYwxPPnkk9x1110ljkVGRrJgwQKefvppRo0axbPPPntO9woKCmLLli0sWrSI6dOn8+233zJz5kyHU1FXdUBwmxKBTkOtlDqb4tNQX3zxxcycOZOUFGvV3ZiYGE6ePMnRo0fx9/dn4sSJPPbYY0RGRjo835H+/fuzcuVK4uLiyM3NZfbs2QwfPpy4uDjy8vKYMGEC//73v4mMjCx1Kuqq5jYlAps95GmJQClVmuLTUE+bNo1du3YxaNAgAOrVq8esWbOIiorisccew2az4eXlxQcffADApEmTGDNmDM2bN2f58uUO79GsWTOmTp3KyJEjMcYwfvx4LrvsMrZs2cKtt95Knn1h9VdeeaXUqairmttMQ733RDIXvbmK927ozfjuzc5+glKq2uk01FVDp6Euhb2JQHsNKaVUMe4TCPLHEbg4H0opVdO4TSCwaa8hpWoF/T96birz93OjQKBTTChV0/n6+hIfH6/BoJKMMcTHx+Pr61uh89yn11B+IMhzcUaUUqUKCwsjOjqa2NhYV2el1vL19SUsLKxC57hNINBpqJWq+by8vGjTpo2rs+F2nFY1JCK+IrJORLaIyA4RecFBGh8R+UZEokRkrYiEOy8/1m8NA0opVZQz2wgygQuMMT2AnsAYERlYLM3twGljTDvgTeBVZ2XmzOyjGgqUUqowpwUCY8kfC+1l/yn+KXwZ8Ln99ffAKMnv51nFdIoJpZRyzKm9hkTEQ0Q2AyeBJcaYtcWStACOABhjcoBEINjBdSaJyAYR2VDZRiSdhloppRxzaiAwxuQaY3oCYUB/EelWyevMMMb0Ncb0DQ0NrVxmCgJB5U5XSqm6qlrGERhjEoDlwJhih2KAlgAi4gkEAvHOyINNdNFipZRyxJm9hkJFpKH9tR9wIbC7WLK5wM3211cBvxonteZqG4FSSjnmzHEEzYDPRcQDK+B8a4yZLyIvAhuMMXOBT4AvRSQKOAU4Z0FOtI1AKaVK47RAYIzZCvRysP/ZQq8zgKudlYfCREsESinlkNvMNaRLVSqllGNuEwh00jmllHLMjQKB9VvjgFJKFeVGgUDbCJRSyhG3CQQ6+6hSSjnmNoHAy2Y9anauLkiglFKFuU0gsNkEm0BOrpYIlFKqMLcJBABeHjaydYkypZQqwv0CQY6WCJRSqjC3CgSeHkKOlgiUUqoI9woENhvZ2kaglFJFuFUg8PIQcrTXkFJKFeFmgcCm3UeVUqoYtwoEnh5Ctg4tVkqpItwqEHjZbFo1pJRSxbhVIPD0EB1QppRSxbhVILAGlGkgUEqpwtwsEAjZOVo1pJRShblVIPC02XRAmVJKFeNWgcDL00aWthEopVQRTgsEItJSRJaLyE4R2SEiDzhIM0JEEkVks/3nWUfXqio+njYys3OdeQullKp1PJ147RzgEWNMpIjUBzaKyBJjzM5i6VYbYy5xYj4K+Hp5kKVtBEopVYTTSgTGmGPGmEj762RgF9DCWfcrDx9PGxlaIlBKqSKqpY1ARMKBXsBaB4cHicgWEflFRLo6Mx8+njYytUSglFJFOLNqCAARqQf8ADxojEkqdjgSaG2MSRGRccAcoL2Da0wCJgG0atWq0nnx8fTQQKCUUsU4tUQgIl5YQeArY8yPxY8bY5KMMSn21wsALxEJcZBuhjGmrzGmb2hoaKXz4+tlIzNHq4aUUqowZ/YaEuATYJcx5o1S0jS1p0NE+tvzE++sPPl4epCda8jV0cVKKVXAmVVDg4G/A9tEZLN931NAKwBjzHTgKuBuEckB0oHrjDFO+5T28bLiXmZOLv7eTq8VU0qpWsFpn4bGmN8AOUuad4F3nZWH4nw8rUCQkZ2Hv3d13VUppWo2txpZ3MDXC4DkjGwX50QppWoOtwoEgX5WIEhI00CglFL53CoQNPS3B4J0DQRKKZXPrQJBfokgUQOBUkoVcKtA0MAeCJI0ECilVAG3CgQBPlYnqdTMHBfnRCmlag63CgT+Xh6ABgKllCrMrQKBzSYEeHuQkqnTTCilVD63CgQA/j6eWiJQSqlC3C4Q1PPxJDVLA4FSSuVzu0DQwNdTu48qpVQhbhcIGvp7s3pfHGlaKlBKKcANA8HKvbEAfPr7IddmRCmlagi3CwQD2zYCIE/XJFBKKcANA8HHN/cDYObvB12cE6WUqhncLhDU8/HEJnA6LRsnroGjlFK1hvsEgj2/wH86wamDPDm2MwBztxx1caaUUsr13CcQ2Lwg+RikxuLnbU018cDXm4k6meLijCmllGtVOBCISJCIdHdGZpwqIMT6nRrLhV2aFOwe/cZK/rv2LxdlSimlXK9cgUBEVohIAxFpBEQCH4nIG87NWhULCLV+R35BE68MVj02suDQU//bpu0FSim3Vd4SQaAxJgm4EvjCGDMAGO28bDlBQCj4NIC9C+G1NrRadCvfjUxCyAOg54tLePjbzaRn6YR0Sin3Ut5A4CkizYBrgPnlOUFEWorIchHZKSI7ROQBB2lERN4RkSgR2SoivSuQ94rx9IaHtsPEH2HwA3B0E/3WTGZvj2/wJpvE9Gx+jIyh87MLeeTbLfy2L85pWVFKqZqkvIHgRWARsN8Ys15E2gL7znJODvCIMaYLMBC4V0S6FEszFmhv/5kEfFDunFeGbyC0GwWjn4eHdsDoF/DaM483vD8sKBkA/BAZzcRP1rI9JtGp2VFKqZqgXIHAGPOdMaa7MeZu+/YBY8yEs5xzzBgTaX+dDOwCWhRLdhlWVZMxxvwJNLSXPJzPwwuGPAijn+cS2x/8MWQLM/7ep0iSybM2MmPVfj77/SAH41KrJVtKKVXdyttY3EFElonIdvt2dxF5urw3EZFwoBewttihFsCRQtvRlAwWiMgkEdkgIhtiY2PLe9vyGfwgdLmcZpve5qLE75h/7yDuGNLGyszpdF5esJvn5+3k+hl/Vu19lVKqhihv1dBHwJNANoAxZitwXXlOFJF6wA/Ag/YG5wozxswwxvQ1xvQNDQ2tzCXKyiCMex3C+sPip+m2/kmeHteJ354YycVdm+BpEwCOJ2Uw9u3VvDhvJ6P+s4KNh0+zLTqR7Nw8snLyznITpZSquTzLmc7fGLNORArvO+s8ziLihRUEvjLG/OggSQzQstB2mH1f9aoXCrf+DCunwfJ/Q+pJwkY/z4d/74sxhpiEdIa8upxdx5LYdcyKZRM++KPg9CYNfFj7VO3qRKWUUvnKWyKIE5HzAAMgIlcBx8o6Qayo8QmwyxhT2piDucBN9t5DA4FEY0yZ13Wq4Y/B2NcgJhI+HAbf3oQc30ZYoA8N/b0AaNHQr8RpJ5IymfnbQd5Yspf0rFySM7J54OtNxKVkVvcTKKVUhUl5BlLZewnNAM4HTgMHgYnGmENlnDMEWA1sg4IuOU8BrQCMMdPtweJdYAyQBtxqjNlQVl769u1rNmwoM8m5y0iENe/BmvchKxn8Q8ga9xam0zh8PD04FJfKmgPxHEvM4J1lpXeeunVwOM/9ratz86qUUuUgIhuNMX0dHqvIiFoRCQBs9l5ALlEtgSBf2inYOQc2fgbHt8MV06H7NUWSpGTm8MbivaVOa31l7xZgoHVwAPePakex6jWllKoW5xwI7IPBPgWSsRqOewNTjDGLqzKj5VGtgSBfZjLMvh4O/w5DHobwwdBqEHidqSY6mpDO+VN/PeulZt0+gN6tG+LvXd7mGaWUOndVEQi2GGN6iMjFwGTgaeBLY4zzRgKXwiWBACArDb69CaKWWNve9aBRW+h9E7QZDqEdCpLuO5HMo99vJSTAmyOn0/D39mTzkYQil2sbEkDf8CD+dXk3fDw9qvNJlFJuqKxAUN6vpfn1GeOwBoDtEHer4/D2h4nfW9VFf62B/b9C9HpY8Kh1fMjD0Pc2qNeE9k3q89O9g4ucfiIpg3/+bztLd50A4EBcKgfiUklMz+aPqHiSM3NoGxLAnPsG08DXq7qfTinlxspbIvgUa6BXG6AH4AGsMMb0KfNEJ3BZicARY+DgSlj3Eey2T8FUrwn0vhn6T7K6pRaTlpXD4Km/cjot2+El/9ajOScSM7hxYCsu7dEcgPjULELq+TjtMZRSdV9VVA3ZgJ7AAWNMgn066jD7wLJqVaMCQT5j4Ogm2LcEjqy1SgsBITDoXjj/AbDZIC8XbFYVUGJaNqfSstgancCnvx9iQu8W7DyWxOx1R0q9xRe39adFkB/HEjIY0j6kup5MKVVHVEUgGAxsNsakishErMbit40xh6s2q2dXIwNBcUfWwdLnrcblkA6AQPppuPpTCB9S6mmH41OZu/koUbEp/LS57GU0H76wA+MimtKqUQDenu6z0JxSqnKqIhBsxaoS6g58BnwMXGOMGV6F+SyXWhEI8q390Pqp1wSi11mlgsZdrMnuWvSB4PNKPXXV3lg+Wn2A0Z2b8NzcHWXe5oe7B9GtRaA2OiulSlUVgSDSGNNbRJ4FYowxn+Tvq+rMnk2tCgSFZSTC6jestoT4KGtf/ebQ/w6roTkpBuo3K6g+KmzEtOUcik/j7wNb07KRHy8v2O3wFjcOaEVYkD+Th7cl8q8EerdqqOMWlFJA1QSClcBC4DZgKHAS2GKMiajKjJZHrQ0E+dJPQ+SXcGI7JMbA4d/Ayx+y0yC0Ewy4CzqMhQZnZuPOzMll97FkerRsWLBv6Gu/cuRUepm3GhfRlPdu6M38rcdYvS+W167q4bTHUkrVbFURCJoCNwDrjTGrRaQVMMIY80XVZvXsan0gKCwvD9Z/DLG7oEFzWD8Tko+C2KB5L2gaAdnp1kI6DZoXOTU3z5CSmcP7y6P4cNWBUm/RuVmDgonyvp40EC8PG31aBznxoZRSNVGVTDEhIk2AfvbNdcaYk1WUvwqpU4GguIwkOBoJW76GY1vhpL1twLs+XPBPGHj3WS/x7/k7+fg3x9Nd5Pt9ygUOJ89TStVdVVEiuAaYBqzAGlw2FHjMGPN9FeazXOp0ICgu4QhELYVFT1lVR/WbQ+e/wXkXWCWG+k1KnGKMISM7j4zsXP71805+jCx9Vu8pYzsxeXjpDdZKqbqjSqaYAC7MLwWISCiw1BhT7ZXObhUI8mUmw7c3w/5lZ/bZvCCkPeTlwJhXoF3p6yHk5Rke/nYz8alZrN4XV+RYu8b1SM/KZfmjI7QbqlJ1WFUEgm2FG4btA8y0sbi65eZAZhLs+QUOLIdt35051v1aGPlPCGpd6unGGO6eFcnCHccdHn91QgT7Y1N5alznqs65UsrFqiIQTMMaQzDbvutaYKsx5okqy2U5uXUgKC4n02pPWPYCpMVb+xq2hpFPWa9TTsLg+x2e+vPWY9z730iHx569pAueHsI1fVvi66VjE5SqC6qqsXgCkD+T2mpjzP+qKH8VooHAAWMgahl8NaHksYiroeUA6Hu7NdVFMVEnk2nVKIAOT/9S6uXHd2/GezdU+5ARpVQVqrKFaWoCDQRlOLkL4vbBngXg0wAO/Xam5xHA0Eet6iMHAcEYQ1ZuHld9sIZtMYkljn90U19OJGVwVZ8wLSUoVQtVOhCISDL2dYqLHwKMMaZB1WSx/DQQVEBOFqz+j7XsZpZ9UTkPb2h0HqSfgguegYiriiywk5tnyMzJZfW+OO76cmOJS17UpQnTrupBoL9Ola1UbaIlAgXpCTDvfms9hSNrITfL2t9hLFz+Pvg3KpI8N88wY9UBLuzSmNFvrCpxuav6hPH3ga2xidA2NIAAH11xTamaTAOBKio3G/78AJY8c2bfoPtg4D3g2wC8AkpUH6Vm5jB51sYS3U8B2jeux9z7hmCzoRPfKVVDaSBQjuXlwfYfYN4DkJ16Zn+70TDxB4enfLfhCI99X/oyFFf0asHT4zsTrAvpKFWjlBUInDaCSERmishJEdleyvERIpIoIpvtP886Ky+qFDYbdL8anoqBS96Ehq2s/VFL4Y2uVmNzRqI135Hd1X1b8v3kQYzsGMrYbk1LXPJ/m2Lo8++lpGbmkJmTy8PfbGbfieTqeiKlVCU4rUQgIsOAFKw1jrs5OD4CeNQYc0lFrqslAidLjYNpDqaduOE7aH8hFJrWOjfPcN5TCxxepl94ELl5hsi/EgD45Oa+jOpcckoMpVT1cFnVkIiEA/M1ENQyudlwaDXsWWh1RU20L6HpHwz/iAS/M9Nh/3kgnqycPESgeUM/Xlmwm6W7Tji87KGp46sj90opB1xSNVROg0Rki4j8IiJdS0skIpNEZIOIbIiNja3O/LknDy9rYrtxr8FD2+GhHRDW3xq9/MFgWPV6QdKBbYMZ1iGUoe1DOS+0HtMn9uayns0dXnb5bpdMWKuUOgtXlggaAHnGmBQRGYe1BnL7s11TSwQutPm/MMc+FXbjLtYiOl4B1liEYiuhHY5P5dWFu1mwrei8RkH+XvwxZRR+3tq7SKnqVCOrhhykPQT0NcaU7J9YiAYCFzt1EH64A2I2UjDW0CcQmveE6/4L3gFFgkJmTi5/xaexNTqRR77bUuRS941sx6MXd6zGzCvlvmpk1ZCINBX7groi0t+el3hX5UeVU6M2cOcyuG899LjB2peZCAdXwist4NNxRZL7eHrQvkl9JvQJ4/Pb+hc59u7yKAZP/ZW4lEw+XLmfI6fSqusplFKFOLPX0GxgBBACnACeA7wAjDHTReQ+4G4gB0gHHjbG/HG262qJoIaJ3w8bP4Ojm6wGZrBKCH1uhqEPw5x7Yfhj0LwXeXmGT/84xNoD8Sze6bhBedKwtjoNtlJOoAPKVPVIjIGVr0Lk50X3h3SE+9YVbGZk5zJ381Hq+Xpyz1clp8K+uk8Y066u9jWPlKrTNBCo6pWTCaumWT/5wvpDYAu4fDp4+RbsDp/yc6mXefu6nlzWs4Uzc6qU29BAoFzDGIiPgulDICfDvlPgwW3QsCUAT8/ZRpdmgfh42vghMpo/9hdtJnp8TEeu7tMSLw9h7pajdG7WgH7hjVBKVYwGAuVaudnWGISvroLj28C3IVz4AnS/rkjpAKxup6fTsrn8vd9Lvdzqx0cSl5JJz5YNkWLdVpVSjmkgUDVDbjas/wQWFlrhtGkEdBgDHcdCiz4Fu+dvPcp9/91U5uUu69mct6/r5azcKlWnaCBQNUtmCuxdCLvmwt7FkGOf1K7rldCgubVgjpcvW6MT+HLNYZIystl9PJnD8SW7l/7n6h5M6BNGckY29X11sRylSqOBQNVcpw7CshdgR7ElsPvcCsMehcAwwFpK862l+3h72b5SL/Xprf0Y2bGxM3OrVK1VIweUKQVYA9Su/gwePwgP74KO9gFpGz+FD4fDpq8gLw8R4cFR7bh/VHvm3HM+V3QPLXGpb9YdYWt0Ak/P2UZeXu36gqOUK2mJQNUsuTnw7d+hUVurlJAUU/T49d/A9u8hahk/DlvAwz8d4L6R7Xh3eVSRZLecH05Gdi7X9GtJ71ZB1fgAStVMWjWkaqe8PNj0pbXWsgOmzTBir/yOxvV9eWXBLj5cdcBhuhsHtKJr80D6twmiXeP6zsyxUjWWBgJVux3bYi2YE9rJCgq5WZCZbE1r0e5CaNGHTM/6DPg5hATqc33/lsxed6TEZRoFeBP5zIUueAClXK+sQOBZ3ZlRqsKaFZpuIn8t5YwkmH2dNb9R1BJ8gM2+kBnaHZ9uz+ApYeTEbGF2dCPAGmtwKjWLnNw8PD20aUypwrREoGq37HTYt8RaRW3RUyUOJ/k05VC6H1dkvUgu1hoIt5wfzj0jziO0vg8iQmxyJqH1fao750pVK60aUu4jPQG2fgO/vgSZieQ074fn0fVE5TXn2qxniCewSPJ6Pp6kZObw9aSBDGwb7KJMK+V8GgiU+8lIAu96VnvCa20hOxWA454tWJrRiedzbiYHTwJIJwcPQhoGsurxkXjYdMoKVTdpIFDuLS+XU+u+xm/TJ/iln4CkaACOmUYEk0gSATySfTe3D27FkDE3YNM2BFUHaSBQqpBfZ7/BBXteKNjONYKHWP8PduW1opVvGl5jX8Z77buAgcs/gOD2kBZXMNJZqdpGA4FSxRkDv71JVr3mJMUd5dTmn2mYEkVjSSj7vMcOQIC2JajaRwOBUmdhjGH9wVPM+3UVO/Yf4kef5wHYlhdOhO1QQbrMjpfhc/XH4Olt7Ug6BrvnQ/drwbdB9WdcqXLSQKBUOZ1MzqD/S8vwIYswiWW/acF5EoMv2VzksZ4HPO2T4zXtDplJcPqQtd3oPGud5iXPQvhQuGkurHkXOo2H4PNc9jxK5dNAoFQFHI5P5XhiBg39vVl/6BRPz9lecOx6j2W84vUJ6bYA/PJSz36xtiNhzFSo3xR8AyEjEXzqAwI2bZRW1UdHFitVAa2DA2gdHABAx6b1aRsSQHJmDpv+SmD6StiY14EDphn+ZPDAyLb4NWzC4MR5tM7YA+1Gwbc3nbnYgeXw/gDrdatB8NeaM8cufhmObYXRz0ODZtX2fBusQn4AABgASURBVEoV57QSgYjMBC4BThpjujk4LsDbwDggDbjFGBN5tutqiUC5UtdnF5KalUvLRn4cOZVe5NjAto24YUBrLm2Vbc2P1GYo/P42/Pbm2S/c51bw8gMERj1jVTGZPOh6BbQ6H07usOZXahphL1HY5eVCXg546shoVTaXVA2JyDAgBfiilEAwDvgHViAYALxtjBlwtutqIFCutOVIAl+sOcwrV0awPzaFsW+vLpHm2Uu6cCg+lfZN6vP3ga2tnZtmQcIRGPKg9YF/dBPMHAM5GRXLgHc9a8GejZ9BcDuIWmrt7/V3GHgPpMZa12/Z39qffBy+utpa86FwW0VeHqQct1aEy3f4D/APgdAOFcuTqhVc1kYgIuHA/FICwYfACmPMbPv2HmCEMeZYWdfUQKBqmiU7T3DnF47/TX55e3+Gti+5iA5gLdmZl2OVHr67BQbcBTt/gpM7reN+jawPdZsnJByuWKaumw3bvi268tvYadB+NMx7wAooexZYCwJ5+UPKCXi7u5XuuQSQMkZY5+VC2inwD7baOaKWQrNeFe9Wm3ISTu6CtsMrdp4zZKXCwikwfAoEtjj36xkDWSlFS2+VuYYI7JwL3gEQE2kF+Er+vWpqIJgPTDXG/GbfXgY8YYwp8T9KRCYBkwBatWrV5/DhCv6nUMqJMrJzue+/m1i664TD431bB/Hd5EFIWR+u+VJOQmK09e3d1z4vkjHWh+/Wb+Cne6x9nS+F41ut3ku75lbRk9gFtYFRz1ofjvMesD7wJ35vzQIbvQE+HmWl6zAGLnwR3usPAaHw6D6rGsy/EURcA97+VrrcHNi/zGo4z+92m5kM04dYva6ejAZPP/CooibL3GwQa4LBcjfIb/sefrgdOl0C13117nn4czosfAIe3l2y/ScxxvqbevkW3Z+ZAvH7YP5DVs+z9R/D7Utg+mDruNhg2OMw8slKZanWB4LCtESgarLFO47zwrydxCQUbT9o0dCPBQ8MZdafhzkvNIAx3SrZOJx0FOo1AZvHmX0HVloN0R5eVlVQUsyZD+uq5NPAKsFkp5UvvV8jaDPMqq46/DuM/CcMf9zqOTW1VdG0jdrCfRutuaFO7ACTe6Z6q7zSTlmz0H44zNoOaAwD74beN0FAiHXftHhrv0+9oucufxlWvmq99g+GS//P6vpbWf/X1/pQv2OZFUB/uAP6T7Ke6V8hZwJOwhFY/pIVeN/oXPI6Qx4q2sZ0xQzocW2lslRTA4FWDak6Kz0rl9X7Ypn05caCfX5eHqRn5wIwfWJvnvlpBwsfGEpwPSc09CYftz7QPLxg9X8g8kur4blZd2h/sdVGgYHPxkNgS6vtot8dcHgNfDrmzHX8g60Pz8Iuftn6gP9oFORmlj9PXS6DrlfCshfglIPV5AJbWh/k+f55AqLXWR/gbYZbASXhMOyaBxFXQ+vz4fh22PYdDH24ZHApbMDdsPaDQs8VAn97GzpfAus+gq3fWvfKF3GNFfTOGwndJsAPd1p/y7+9BX4Olj7NyYT9y6HDxVZ1zmttrb/bNV9YM+Lmr7JXr6nVNgNWtdxHI61SUcQ1VlXe2dz5K7Toc/Z0DtTUQDAeuI8zjcXvGGPO+hVAA4GqLU6lZtH7X0sA6NGyIXuOJ5GRnVckTaCfF1ueu8gV2bPkZJbe4yg3x6quSfgL5txjLQIE8PCuM43MiTFWFdLh32H+gzBpJcy82GoEzw8iPW+E5GOw/9eqzXtYP4hef27XaH8R7FtcdprWQ+Dwb9brvrdbjfVRy+DXf1uDCOs1hp8fsY4Pe9z6oJ5duW/tRfS9DTbMLLrv6dgz1WsV5KpeQ7OBEUAIcAJ4DvACMMZMt3cffRcYg9V99NazVQuBBgJV+yRnZFPf14t9J5K58M1VJY7fcn443VoEclWfMKJPpxEc4IOft4eDK7lY8gnrW3nTEt/rzhyv3wRysiAnHTx94cR2qyE5KQbeKnTesMeh89+sEgpYjdrLX4G4PZXPn29D60M4MAwiPy89nU8DewP58aL7L/yXde6276yGdFfxC4LJv1t/s0/sS6tGXG31DDuHhnUdWaxUDfHT5hhmr/uLS3u0YFtMQpG1lYd3CGXl3lh6tWrI/+4ZXOS8Ls8upF94Iz6/rYL15jVNzEYrMJTWiJsYY9Xnn9gBh36DJc+cOXb151b7iAis/wRST8LoF2Dpc3BgBTy00+rxYwzE7QUPb6vEc+RP6H2zVdWTnmBdf8MnZ77FQ9Fv2hmJsP1HWPkaJB89k+be9fBevzPbl7xllYIAgsKh10SrlADQrKd1n/zuvTfPgz2/wJ/vWx/ym/8LAyZZz7N3Iaz90Kqa8w2EJl2tEldOJvynEzRoAZNXl92Tqxw0EChVAx2OT2X4tBUOj42PaMaeE8n8eM/5NPD1InzKzwAcmnqmATMhLYv07FyaBfpVR3ZdI+mY9YGam32mF1JVMAbST1uN7/6Nio6nyJeTaZVUQtpb39IbtbXq8yO/gA5joWU/q4F6+UtWoGnW3ep9FBQOYX0hdg+smGo1BDdqY90zJ7Nkb6GyZCZbPaCq4Nk1EChVQ1327m9siU6kSQMfbCLccn44r/yyu0iaS7o3Y/5Wqw/FqsdG0riBD75eHvR6cTGn07KLBAelSqNzDSlVQ711XS9eW7ibqRO6E+jnhTGGQ/FpzF73V0Ga/CAAMGzacnw8bWx4ejSn07IBawrtco1RUKoUWiJQqobKLy2czaZnLiQooHI9SZT7KKtEoPPgKlVDzbpjAD/ecz4AXZuXvujNLZ+uY8IHf3Ay+cy8RQfjyjFFtlJ2GgiUqqHq+3rRu1UQH9zYm1m3D+DQ1PFc37/koKkt0YlsPHyaf/x3EwBzNsUw8vUV/B4VV91ZVrWUBgKlarixEc0Kqn5evqIbO164mMcu7lgi3dqDpzhyKo2v1lpzcX274Qhj317Nawt3c830NSXSK5VPG4uVqkVEhAAfT3w8HX+HG/ra8oLXP222+sDvOpYEQE5uHp4eNt5fEcWANsH0ae1gqgTllrREoFQtNKF3GNf0DWPFoyO4Y0ibcp3T7p+/sGjHcV5buIcJH/xRsP90apazsqlqCe01pFQdkZdnyDOGuVuOsmTnCX7ZfrzM9L8+MpwL/rMSgB/vOZ/erbSEUJfpgDKl3NCB2BTyDIx+Y6XD4/lTWuQ7NHU8q/fFsvmvBO67oJ2OTahjNBAo5cby8gwRzy8iNSu33Odc0asFT43rTJC/F54eWoNcF+g4AqXcmM0m7HhxDDP+XnIe+9cmdKd7WGCJ/f/bFEO/l5ZyV6H1FFTdpb2GlHITF3Vtyvs39mbJzhP0CAtkRMfGhIcEcE2/lgWT2hW3bPdJftsXx8RP1vLYxR25qk8YTRpUYNI0VSto1ZBSqtRA4Mj0ib25uGvTEm0I/9sUzYA2wTRvWIdnQ63FdNI5pVSZfnlgKCmZOeTmGd5bHsXGw6fpEdaQNQfiS6SdPCuSwe2CGd25CXM2H2XW7f2xifDQN1vo0KQeix+q/OIpyjW0RKCUKiL/M0FEiE3OZPKsjWw8fLpc53rahKiXx3EqNYsv1hwiOSOHu4a1pbFWJ7mc9hpSSp2Tf8zeRHCANw+N7sDincd57Put5T43okUg/7vnfO195GIaCJRSVW7JzhMcjk8lokUg187486zpbx7Umuf+1hWbTccnuIK2ESilqtyFXZoUvF780DAuenMVAI3r+3AyObNE+s/XHOayXi1ISMti/pZjjItoRkN/LwL9vGjfpH615VuVpIFAKXXOOhT6IF/71ChmrzvCi/N3kJGdVyTdle+fmePox00xRY79+eQo1h06xSURzbTUUM2cWjUkImOAtwEP4GNjzNRix28BpgH5/yLeNcZ8XNY1tWpIqZrpUFwq2bl5Jb7dX/vhGtYePFWha31xW3+GdQgFYNGO4/h6eTDcvq0qxyUji0XEA3gPGAt0Aa4XkS4Okn5jjOlp/ykzCCilaq7wkACHVTzjIpoBcOfQNjQP9GW8fTvQz6vUa900cx0Pfr0JYwx3fbmRm2euY5t92c7Iv07T7qkFPPfTdic8hXtyWolARAYBzxtjLrZvPwlgjHmlUJpbgL7GmPvKe10tEShVuxhj2H08mc7NGhR0TU3KyKG+jyf3zY5kwbbjPHpRB15fvLfEuS0a+hGTkF6wffOg1ny+5nDB9opHR+BhE1o28nf+g9RyrmosbgEcKbQdDQxwkG6CiAwD9gIPGWOOFE8gIpOASQCtWpVcqk8pVXOJCJ2bNSh4DWdKA+/d0BtjrPmQWgT58eh3W8nNO/PltHAQAIoEAYARr68A4MDL4wraFbZFJxJa34emgTp2obxc3Vg8D5htjMkUkbuAz4ELiicyxswAZoBVIqjeLCqlnEVEyJ+p4opeYew5nsL0lfv5bvIg/twfj5enjfERzYqsvObIXbM2cv55waRm5vD64r34e3uw88UxDtMmZWTj7+Wh4xoKcWnVULH0HsApY0zJqRAL0aohpequrJw8fo+KY2SnxkX2/7r7BMt3x/Lln4fpH96IsEZ+/BgZU8pVLNf2bcmptCwu6NSYkR0bY7NBaD0f2jy5AIB3b+jFJd2bO+1ZahqXDCgTEU+s6p5RWL2C1gM3GGN2FErTzBhzzP76CuAJY8zAsq6rgUAp95WelYuvlw0Rof9LSx2OVyhLhyb12HsipWD70NTxVZ3FGsslbQTGmBwRuQ9YhNV9dKYxZoeIvAhsMMbMBe4XkUuBHOAUcIuz8qOUqv38vD0KXq/752hOJmdwMimTNiEBfLjqAO8s21fm+YWDAMADX2/C02ajT+sgvlhziDn3DubSd3/jkYs6cnHXpuTk5pGckYO3p40AH1fXpDuPTjGhlKoztkUn4uftQQNfTybP2siIjo15b3kUmTl5Zz8Z+Pfl3Xh6jtUttUdYIFvsXVYD/byYPPw8UjNzePTijk7LvzPpXENKKbcV+dfpghHNr1/dg0e/28K4iKYs2Ha8Utf74rb+DGkXUmT0szGGqQt3c0WvFnRq2qBK8l3VNBAopdza1ugE/rN4LzNu6oOPp1W99OvuE+w6lsy0RXsAGNIuhK3RCSRl5Jz1ekH+Xtw2uA2HT6Ux7aruxKVk0e+lpTQP9OWPJ0cVSbt4x3E6Nq1P6+AATiZn8Mi3W3jp8ghaBVfv2AcNBEopVYov1hxiYNtg2jeuh4hgjGHnsSRemLeTdeWYGmP14yPJyM7lQvuke789MZLL3/sDYwz3jmzHi/N3EuDtwY4Xx/D0nG3M+vMvAN66tieX92rhzEcrQgOBUkpVQkxCOsEB3tz++Xp+jyq5WhtYi/HcP6o9bywpOTK6sPsvaEdcahb/XftXwb6Dr4wrseSns2ggUEqpc5CelcurC3fz2R+HuGNIG85vF8ziHSf4en2JiRAq7NIezWnSwIc7h7WlcX1rNPTBuFQa1/fBz8ujymZi1UCglFJV4FhiOiH1fPCyj0pOzsgm4vnFRdIMaNOIni0bMn/rMYa0C+GbDeULFt1aNCA8OID5W48V7LuydwtaBvlzXf+WBPl74+vlUcYVyqaBQCmlnOSjVQeYu+Uo8/4xBGNMkaqerJw8Ojz9S4lzmjbw5XhSRoXv9cCo9jx0YYdK5VNXKFNKKSe5c1hb7hzWFqBEfb+3p439L4/jizWH+D0qnqW7TjD1ygjGdW/GrqNJrNoXy3vL95f7Xh2bOmclNy0RKKWUC4VP+bngdf/wRnxxe38Oxacy5q3VAPRpHcTGw6fp2KQ+vzwwtNJtBloiUEqpGmrD06PZcTSJ7TGJ3D38PGw2KTIo7fvJg/g9Kp5B5wU7bQlPDQRKKeVCIfV8GN4htMRSnN9MGsjBuFREhCHtQ5yaBw0ESilVAw1oG8yAtsHVci9dmUEppdycBgKllHJzGgiUUsrNaSBQSik3p4FAKaXcnAYCpZRycxoIlFLKzWkgUEopN1fr5hoSkVjgcCVPDwHiqjA7tYE+s3vQZ3YP5/LMrY0xoY4O1LpAcC5EZENpky7VVfrM7kGf2T0465m1akgppdycBgKllHJz7hYIZrg6Ay6gz+we9Jndg1Oe2a3aCJRSSpXkbiUCpZRSxWggUEopN+c2gUBExojIHhGJEpEprs5PVRGRliKyXER2isgOEXnAvr+RiCwRkX3230H2/SIi79j/DltFpLdrn6ByRMRDRDaJyHz7dhsRWWt/rm9ExNu+38e+HWU/Hu7KfJ8LEWkoIt+LyG4R2SUig+ry+ywiD9n/TW8Xkdki4lsX32cRmSkiJ0Vke6F9FX5fReRme/p9InJzRfLgFoFARDyA94CxQBfgehHp4tpcVZkc4BFjTBdgIHCv/dmmAMuMMe2BZfZtsP4G7e0/k4APqj/LVeIBYFeh7VeBN40x7YDTwO32/bcDp+3737Snq63eBhYaYzoBPbCev06+zyLSArgf6GuM6QZ4ANdRN9/nz4AxxfZV6H0VkUbAc8AAoD/wXH7wKBdjTJ3/AQYBiwptPwk86ep8OelZfwIuBPYAzez7mgF77K8/BK4vlL4gXW35AcLs/zkuAOYDgjXa0rP4+w0sAgbZX3va04mrn6ESzxwIHCye97r6PgMtgCNAI/v7Nh+4uK6+z0A4sL2y7ytwPfBhof1F0p3txy1KBJz5R5Uv2r6vTrEXh3sBa4Emxphj9kPHgSb213Xhb/EW8DiQZ98OBhKMMTn27cLPVPC89uOJ9vS1TRsgFvjUXiX2sYgEUEffZ2NMDPA68BdwDOt920jdf5/zVfR9Paf3210CQZ0nIvWAH4AHjTFJhY8Z6ytCnegnLCKXACeNMRtdnZdq5gn0Bj4wxvQCUjlTXQDUufc5CLgMKwA2BwIoWX3iFqrjfXWXQBADtCy0HWbfVyeIiBdWEPjKGPOjffcJEWlmP94MOGnfX9v/FoOBS0XkEPA1VvXQ20BDEfG0pyn8TAXPaz8eCMRXZ4arSDQQbYxZa9/+Hisw1NX3eTRw0BgTa4zJBn7Eeu/r+vucr6Lv6zm93+4SCNYD7e09DryxGp3mujhPVUJEBPgE2GWMeaPQoblAfs+Bm7HaDvL332TvfTAQSCxUBK3xjDFPGmPCjDHhWO/jr8aYG4HlwFX2ZMWfN//vcJU9fa371myMOQ4cEZGO9l2jgJ3U0fcZq0pooIj42/+N5z9vnX6fC6no+7oIuEhEguylqYvs+8rH1Y0k1dgYMw7YC+wH/unq/FThcw3BKjZuBTbbf8Zh1Y8uA/YBS4FG9vSC1YNqP7ANq1eGy5+jks8+Aphvf90WWAdEAd8BPvb9vvbtKPvxtq7O9zk8b09gg/29ngME1eX3GXgB2A1sB74EfOri+wzMxmoHycYq+d1emfcVuM3+/FHArRXJg04xoZRSbs5dqoaUUkqVQgOBUkq5OQ0ESinl5jQQKKWUm9NAoJRSbk4DgXI7IvKH/Xe4iNxQxdd+ytG9lKrJtPuoclsiMgJ41BhzSQXO8TRn5rpxdDzFGFOvKvKnVHXREoFyOyKSYn85FRgqIpvtc997iMg0EVlvn+v9Lnv6ESKyWkTmYo1uRUTmiMhG+3z5k+z7pgJ+9ut9Vfhe9pGg0+xz628TkWsLXXuFnFln4Cv7SFpEZKpY60xsFZHXq/NvpNyL59mTKFVnTaFQicD+gZ5ojOknIj7A7yKy2J62N9DNGHPQvn2bMeaUiPgB60XkB2PMFBG5zxjT08G9rsQaGdwDCLGfs8p+rBfQFTgK/A4MFpFdwBVAJ2OMEZGGVf70StlpiUCpMy7CmsdlM9ZU3sFYC4AArCsUBADuF5EtwJ9Yk321p2xDgNnGmFxjzAlgJdCv0LWjjTF5WFOEhGNNo5wBfCIiVwJp5/x0SpVCA4FSZwjwD2NMT/tPG2NMfokgtSCR1bYwGmshlB7AJqy5biors9DrXKyFV3KwVpr6HrgEWHgO11eqTBoIlDtLBuoX2l4E3G2f1hsR6WBf/KW4QKxlEdNEpBPWEqH5svPPL2Y1cK29HSIUGIY1OZpD9vUlAo0xC4CHsKqUlHIKbSNQ7mwrkGuv4vkMa12DcCDS3mAbC1zu4LyFwGR7Pf4erOqhfDOArSISaazpsfP9D2tpxS1Ys8U+bow5bg8kjtQHfhIRX6ySysOVe0Slzk67jyqllJvTqiGllHJzGgiUUsrNaSBQSik3p4FAKaXcnAYCpZRycxoIlFLKzWkgUEopN/f/o+LOgMI8qBgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}